[{"content":"初次发布于我的个人文档。（每次都是个人文档优先发布哦）\n本文想简要介绍一下如何用计算机是如何用迭代法计算方程和方程组的根的。\n不动点迭代 在高中阶段你可能学习过这样的叫蛛网图的东西：\n蛛网图迭代的极限就是函数的不动点。\n所谓不动点迭代就是利用了这样的性质。\n一般地，我们想求解方程f(x)=0，如果我们可以将这个方程转化为x=g(x)，那么g(X)的不动点就是f(x)的零点。\n而g(x)的不动点又是蛛网图迭代的极限。\n如果用代数语言表示的话，就是迭代公式\n$$x_{k+1}=g(x_k)$$这就是不动点迭代求方程的根的方法。\n当然，如果要更严谨化的说明的话，就是下面的压缩映像原理：\n设g(x)在[a,b]上具有连续的一阶导数，且满足以下条件：\n1.$\\forall x \\in [a,b],g(x) \\in [a,b]$\n2.$\\exist 0 \\le L \u0026lt;1,s.t. \\forall x\\in [a,b],|g\u0026rsquo;(x)|\\le L$\n则迭代过程\n$x_{k+1}=g(x_k)$收敛，且有误差估计式：\n$|x^*-x_k|\\le \\frac{L^k}{1-L}|x_1-x_0|$\n从误差估计式看，k越大估计值$x_k$会离准确值$x^*$越来越近。\n这就足以为不动点迭代法背书了。\n牛顿迭代法 将不动点迭代进一步推广就能得到牛顿迭代法。\n前面我们知道，我们想求解方程f(x)=0，如果我们可以将这个方程转化为x=g(x)，然后用迭代公式$x_{k+1}=g(x_k)$求解。\n但是我们不知道如何把方程转化为x=g(x)，牛顿迭代法就是解决了这个问题。\n思路其实也非常简单，我们知道微分有dy=f\u0026rsquo;(x)dx，于是$f(x)-f(x_k) \\approx f\u0026rsquo;(x_k)(x-x_k)$。\n从而$f(x)=f(x_k)+f\u0026rsquo;(x_k)(x-x_k)=0$\n那么$x=x_k-\\frac{f(x_k)}{f\u0026rsquo;(x_k)}$，完成啦！\n我们把f(x)=0转化为了x=g(x)的形式了，从而再使用不动点迭代得到f(X)根的迭代公式：\n$x_{k+1}=x_k-\\frac{f(x_k)}{f\u0026rsquo;(x_k)}$\n这就是牛顿迭代法。\n弦截法 对于某些函数其导数不便于求解，所以我们可以用差商替代导数，这就是弦截法了。\n用$f\u0026rsquo;(x) \\approx \\frac{f(x_k)-f(x_0)}{x_k-x_0}$代入牛顿迭代法，就是弦截法了。\n如果用$f\u0026rsquo;(x) \\approx \\frac{f(x_k)-f(x_{k-1})}{x_k-x_{k-1}}$代入牛顿迭代法，就是快速弦截法了。\n雅可比迭代法 对于线性方程组，方法其实是类似的。\n线性方程组AX=b如果我们可以将其化为X=BX+f，那么用不动点迭代就有迭代公式\n$X_{k+1}=BX_k+f$\n这是我们线性方程组迭代法的基石。\n它的误差：\n$e_{k+1}=|x^-x_{k+1}|=|BX^+f-(BX_{k}+f)|=B|X^*-X_k|=Be_k$\n从而，$e_k=B^ke_0$\n那么如果$B^k$能收敛于0的话该迭代法就收敛了，可以演算得到这等价于B的谱半径（最大特征值）小于1。\n但是还是一样的，不动点迭代法说的轻巧，但是你怎么把AX=b转化成X=BX+f呢？\n其中的一种方法就是雅可比迭代法了。\n对方程组AX=b，我们将A分解为对角阵D，下三角矩阵L，上三角矩阵U使得\nA=D-L-U。\n（值得一提的是，这个分解是相当容易的，D就是A的对角元，L取A的下三角去掉主对角线，U取A的上三角去掉主对角线即可）\n那么AX=b就是\n(D-L-U)X=b\n然后移项得\nDX=(L+U)X+b\n从而$X=D^{-1}(L+U)X+D^{-1}b$\n完事了，已经变成X=BX+f的形式了，所以就有迭代公式\n$X_{k+1}=D^{-1}(L+U)X_k+D^{-1}b$\n这就是雅可比迭代法了。\n但是这个方法可以稍微变一下，我们移项的时候不一定要把L和U全部移走，这就是高斯-赛德尔迭代法了。\n高斯-赛德尔迭代法 还是安装雅可比迭代的步骤我们得到，(D-L-U)X=b移项但是只移U得到\n(D-L)X=UX+b\n然后得到$X=(D-L)^{-1}UX+(D-L)^{-1}b$\n于是就有迭代公式$X_{k+1}=(D-L)^{-1}UX_k+(D-L)^{-1}b$\n但是我们一般不会这么使用，而是再等式两边再乘以D-L得到\n$(D-L)X_{k+1}=UX_k+b$\n从而$DX_{k+1}=LX_{k+1}+UX_k+b$\n所以$X_{k+1}=D^{-1}LX_{k+1}+D^{-1}UX_k+D^{-1}B$\n这才是我们一般最爱用的高斯-赛德尔迭代公式。\n","date":"2024-11-29T14:11:03+08:00","permalink":"https://ColaBlack.github.io/p/%E6%96%B9%E7%A8%8B%E6%B1%82%E6%A0%B9%E7%9A%84%E8%BF%AD%E4%BB%A3%E6%B3%95/","title":"方程求根的迭代法"},{"content":"初次发布于我的个人文档。（每次都是个人文档优先发布哦）\n本文简要介绍一下主成分分析和因子分析的原理，但是不涉及具体代码实现。这是因为现在已经有很多现成的软件或库实现了这两个算法，读者只需要一两句简单的命令就可以使用了，所以没有必要在这里讲解。而且你可能会在Python R MATLAB SPSS等多种不同的软件中使用，无论选哪个软件的代码实现都没有特别强的代表性。\n主成分分析 如果你手上有一组数据，例如是大家的语文数学英语成绩。但是现在有一个问题，咱们的试卷出得有那么一点点不好，大家的成绩都集中在一起了，也就是试卷的区分度不大。现在，我们有没有办法补救呢？\n注意：这只是一个例子而已，自然是不考虑我们进行各种变换之后的现实问题，例如这样搞成绩会不公平啊什么的。\n总之，我们的核心问题是，有没有办法对现有数据进行变换，使得数据的每一个个体尽可能被分开。\n这就是主成分分析的一个可以选择的切入点。\n那我们要选择什么样的变换呢？以及有没有办法将一个群体之间的不同个体距离拉远。\n以p维正态分布为例进行可行性探索 嗯，对我们先拿p维正态分布探索一下我们想法的可行性。\n我们假设p维随机向量X服从协方差阵为$\\Sigma$，均值向量为$\\mu$的p维正态分布。\n那么X的概率密度函数就是$P(x)=\\frac{1}{(2\\pi)^{\\frac{p}{2}}|\\Sigma|^{\\frac{1}{2}}}e^{-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)}$，我们来观察其概率密度等高线，显然，这里只有e的指数是变量，所以概率密度等高线满足：\n$$-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)=C_1$$也就是$(x-\\mu)^T\\Sigma^{-1}(x-\\mu)=C_2$\n我们可以对$\\Sigma $进行谱分解。\n谱分解说明：\n根据线性代数的知识我们可以知道，任意实对称阵A可以正交相似对角化，即\n$\\forall 实对称矩阵A,\\exist正交阵Q和对角阵\\Lambda，使得A=Q\\Lambda Q^T$\n如果我们已知A的特征值$\\lambda_1,\\lambda_2,\u0026hellip;,\\lambda_n$和对应的特征向量$e_1,e_2,\u0026hellip;,e_n$，则\nQ=($e_1,e_2,\u0026hellip;,e_n$)，$\\Lambda =diag(\\lambda_1,\\lambda_2,\u0026hellip;,\\lambda_n)$\n这意味着:\n$$A=Q\\Lambda Q^T$$$$=(e_1,e_2,...,e_n)diag(\\lambda_1,\\lambda_2,...,\\lambda_n)(e_1,e_2,...,e_n)^T$$$$=(\\lambda_1 e_1,\\lambda_2 e_2,...,\\lambda_n e_n)(e_1,e_2,...,e_n)^T$$$$=\\lambda_1 e_1 e_1^T + \\lambda_2 e_2 e_2^T +...+ \\lambda_n e_n e_n^T$$$$=\\sum_{i=1}^n\\lambda_i e_i e_i^T$$这就是谱分解了。\n我们假设$\\Sigma$的特征值为$\\lambda_1,\\lambda_2,\u0026hellip;,\\lambda_p$，对应的特征向量为$e_1,e_2,\u0026hellip;,e_p$，那么$\\Sigma$就可以谱分解为\n$\\Sigma=\\sum_{i=1}^p\\lambda_i e_i e_i^T$，将他代入概率密度等高线方程就有，\n$(x-\\mu)^T{(\\sum_{i=1}^p\\lambda_i e_i e_i^T)}^{-1}(x-\\mu)=C_2$\n也就是，\n$$\\sum_{i=1}^p\\frac{[e_i(x-\\mu)]^T[e_i(x-\\mu)]}{C_2}=1$$这是p维的类似椭圆的方程，当p=2时这就是椭圆方程。\n这意味着，概率密度等高线是同样有着长轴和短轴。\n因而，这意味着如果我们将原始变量X进行正交变换将坐标轴旋转到长轴上就可以达成我们的目标将一个群体之间的不同个体距离拉远。\n演算 接下来，我们有了方向就可以进行推演了。\n我们要将原始变量X进行正交变换得到新的一组变量，这从几何看就是进行坐标轴旋转。\n总之，从代数角度看就是，设p维随机向量X=$(x_1,x_2,\u0026hellip;,x_p)$的协方差阵为$\\Sigma$。\n那么我们就是要找一组新的变量Z=$(z_1,z_2,\u0026hellip;,z_p)$使得（新变量被称为主成分）\n$$z_1=a_{11}x_1+a_{12}x_2+...+a_{1p}x_p=a_1^TX$$$$z_2=a_{21}x_1+a_{22}x_2+...+a_{2p}x_p=a_2^TX$$\u0026hellip;\n$$z_p=a_{p1}x_1+a_{p2}x_2+...+a_{pp}x_p=a_p^TX$$而此时，$var(z_j)=a_j^T\\Sigma a_j,cov(z_j,z_k)=a_j^T\\Sigma a_k$\n我们前面说了，我们希望将一个群体之间的不同个体距离拉远，也就是要最大化新变量Z的方差，与此同时我们自然希望各个新变量之间无关也就是：\n最大化$var(z_j)$，希望$cov(z_j,z_k)=0$\n对于$z_1$来说就是希望最大化$a_1^T\\Sigma a_1$，但是显然我们可以通过无限扩大$a_1$的长度来实现最大化$z_1$的方差，这是我们不期望看到的。\n所以我们再额外要求$z_1$的长度是1即$a_1^Ta_1=1$。\n这样的话其实我们就是在最大化$a_1^T\\Sigma a_1=\\frac{a_1^T\\Sigma a_1}{a_1^Ta_1}$（注意哦，现在分母为1所以除了等于没除）。\n类似地，我们对$z_2$会要求$a_2^Ta_2=1$，并且$cov(z_2,z_1)=a_2^T\\Sigma a_1=0$\n最大化$a_2^T\\Sigma a_2$。\n以此类推，但是到最后一个变量$z_p$我们只能要求最小化$a_p^T\\Sigma a_p$了，因为这个对应的是前面说的高维椭圆的短轴，是最小的。\n那么，怎么进行最小化呢？\n一般的教材这里就是上拉格朗日乘数法了，计算比较复杂我就不说了。给个结论吧。\n$\\forall a \\in R^p,\\Sigma \\in M_p且\\Sigma为对称矩阵。$\n设$(\\lambda_j,e_j)$为$\\Sigma$的特征值、单位特征向量。\n$$a\\neq 0, a⊥e_1,e_2,...,e_{j-1},$$$$max \\frac{a^T\\Sigma a}{a^T a}=\\lambda_j在a=e_j时取到最大。$$ 利用上述结论就可以知道，X的第j个主成分$z_j=e_j^TX$\n且$var(z_j)=e_j^T\\Sigma e_j$\n注意$(\\lambda_j,e_j)$为$\\Sigma$的特征值、单位特征向量。\n所以$\\Sigma e_j =\\lambda_j e_j,e_j^Te_j=1$\n因而$var(z_j)=e_j^T\\Sigma e_j=e_j^T \\lambda_j e_j=\\lambda_j e^T_je_j=\\lambda_j$。\n所以，X的第j个主成分$z_j$是其协方差矩阵$\\Sigma$的第j个单位特征向量乘以原始变量X，并且第j个主成分的方差就是$\\Sigma$第j个特征值$\\lambda_j$。\n这就是主成分分析的结论。\n更进一步的，如果我们对原始变量进行标准化然后再进行主成分分析，可以证明这相当于对原始变量的相关系数矩阵R进行对应的主成分分析。\n降维 从上面的推导我们可以看到对p维向量进行主成分分析只能得到p个主成分，似乎不能降维啊。那么我们一般说的降维是怎么回事？\n前面我们知道，第j个主成分的方差就是$\\Sigma$第j个特征值$\\lambda_j$。\n如果我们将全部的主成分的方差求和，那就是对$\\Sigma$全部的特征值的求和，也就是$\\Sigma$的迹，也就是X各个分量的方差的和。\n所以到现在为止我们还没有损失任何一点点方差。\n如果降维的话就会损失方差了，这是因为所谓的降维就是将各个特征值从大到小排列，然后去掉比较小的特征值和对应的主成分。\n这样的话就会损失方差了，也就损失了部分信息。这就是所谓的利用主成分分析进行降维。\n因子分析 那么因子分析是什么？\n还是看学生成绩数据吧，从学生的成绩上我们可以看到，优秀的学生似乎各科成绩都很好。也许你还会发现，各科成绩高度相关，这意味着他们可能由某一个潜在变量决定（智商）。\n因子分析就是由原始数据寻找这样的潜变量。\n由于潜变量的数量往往少于原始变量的数量，所以因子分析也是一种降维方法。\n因子分析建立了一个因子模型，它认为原始变量Y是各个潜变量的线性组合，即\n$$Y_i=l_{i1}F_1+l_{i2}F_2+...+l_{im}F_m+\\epsilon_i$$其中，$F_j$是潜变量也叫公共因子，我们假设有m个，当然一般要求m不大于原始变量的个数p。\n系数$l_ij$被称为因子载荷，$Y_i$则是原始变量而$\\epsilon_i$是类似误差的特殊因子。\n我们还对公共因子提了一些基础的要求，首先$F_i,F_j$不相关（正交），$F_i,\\epsilon_j、\\epsilon_i,\\epsilon_j$不相关，来保持各个变量之间的独立性。\n当然，因子模型用矩阵表示更简洁，就是\n$Y=AF+\\epsilon$\n那前面说的那些要求用矩阵表示就是：\n$m \\le p$ cov(F,$\\epsilon$)=0 $D_F=var(F)=单位阵I_m$ $D_\\epsilon=var(\\epsilon)=diag(\\sigma_1^2,\\sigma_2^2,\u0026hellip;,\\sigma_p^2) $ 而因子模型最重要的新增是协方差阵的矩阵分解：\n$var(X)=\\Sigma=cov(AF+\\epsilon,AF+\\epsilon)=Acov(F,F)A^{-1}+cov(\\epsilon,\\epsilon)=AA^{-1}+D_\\epsilon$\n演算 那么如何求解因子模型中未知的A和$\\epsilon$呢？\n答案是利用协方差矩阵的矩阵分解：\n$\\Sigma=AA^{-1}+D_\\epsilon$\n而前面我们说过$\\Sigma$可以分解为$Q\\Lambda Q^T$，其中$Q=($e_1,e_2,\u0026hellip;,e_n$)，$$\\Lambda =diag(\\lambda_1,\\lambda_2,\u0026hellip;,\\lambda_n)$\n我们再进行小小的变换，定义$\\Lambda_2=(e_1\\sqrt{\\lambda_1},e_2\\sqrt{\\lambda_2},\u0026hellip;,e_p\\sqrt{\\lambda_p})$，\n则$\\Sigma=\\Lambda_2 \\Lambda_2$。\n当$\\Sigma$的后p-m个特征值很小的时候，我们就可以忽略掉后面的项，用$\\Lambda_2$的前m项估计A，从而$D_\\epsilon=\\Sigma-AA^{-1}$也就可以计算了。\n这就是因子分析的主成分法求解。\n主轴因子法 除此之外因子分析还有一个常用的算法是主轴因子法，推导比较复杂我就只说思路了。\n我们知道\n$\\Sigma=AA^{-1}+D_\\epsilon$\n那么如果我们先估计$D_\\epsilon$在分解也可以得到A。\n总思路是这样的，不过如果你去翻阅各种资料的话，可能还会遇到约相关阵的说法，\n也就是先把原始变量进行标准化从而$\\Sigma=原始变量的相关系数R$再定义$R^*=R-D_\\epsilon=AA^{-1}$，\n然后估计$R^*$再计算A和$D_\\epsilon$也是可以的。\n","date":"2024-11-27T12:09:07+08:00","permalink":"https://ColaBlack.github.io/p/%E9%99%8D%E7%BB%B4%E6%96%B9%E6%B3%95-%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%E5%92%8C%E5%9B%A0%E5%AD%90%E5%88%86%E6%9E%90/","title":"降维方法 主成分分析和因子分析"},{"content":"初次发布于我的个人文档。（每次都是个人文档优先发布哦）\n本期是基于我刚刚完成的SmartCanvas项目简要介绍一下如何在Windows上部署kafka。\n值得一提的是，kafka是一个大数据场景下常用的分布式基于消息订阅模型的开源流处理平台，在SmartCanvas中当做消息队列使用。\n注意看他的定位，大数据场景、分布式等词，其实意味着kafka需要依托于服务器集群环境，所以他正常的操作还是安装在linux集群上，本文在Windows上安装只是安装一个单机的开发时测试用的kafka。\n1.下载kafka安装包 前往kafka官网下载，\n本文选择的是 kafka_2.13-3.9.0.tgz，只需要下载3.9.0\nBinary downloads:\nScala 2.12 - kafka_2.12-3.9.0.tgz (asc, sha512) Scala 2.13 - kafka_2.13-3.9.0.tgz (asc, sha512) 选择下面那个就可以了。\n这里简单说明一下\nSupported releases 支持版本\n3.9.0\nReleased November 6, 2024 发布于 2024 年 11 月 6 日\nRelease Notes 发布说明\nDocker image: apache/kafka:3.9.0. Docker 镜像：apache/kafka:3.9.0.\nDocker Native image: apache/kafka-native:3.9.0. Docker 原生镜像：apache/kafka-native:3.9.0.\nSource download: kafka-3.9.0-src.tgz (asc, sha512) 源代码下载：kafka-3.9.0-src.tgz (asc, sha512)\nBinary downloads:\n二进制下载：\nScala 2.12 - kafka_2.12-3.9.0.tgz (asc, sha512) Scala 2.12 - kafka_2.12-3.9.0.tgz (asc, sha512) Scala 2.13 - kafka_2.13-3.9.0.tgz (asc, sha512) Scala 2.13 - kafka_2.13-3.9.0.tgz (asc, sha512) We build for multiple versions of Scala. This only matters if you are using Scala and you want a version built for the same Scala version you use. Otherwise, any version should work (2.13 is recommended).\n我们为多个版本的 Scala 进行构建。这只有在您使用 Scala 并且希望使用与您使用的相同 Scala 版本构建的版本时才重要。否则，任何版本都应该可以工作（推荐使用 2.13）。\nkafka 3.9.0在官网上是的这样的，\n额，下面的中文官网是没有的，是已经翻译之后的。\nkafka提供了三种下载方式，通过docker镜像可以一键安装部署。\n通过源代码下载，你将获得kafka的源代码，你可以自行编译。\n下面的二进制下载则是打包后能直接运行的应用程序，我们这次就是选择的这个方式。\n但是你会看到二进制下载有两种，什么2.12 2.13之类的。\n这是scala的版本，kafka是基于scala构建的所以这里有不同版本的scala编译的程序。\n虽然kafka是基于scala构建的，但scala和kotlin类似也是一门jvm语言，所以你运行的话只需要准备java环境就可以了不需要下载scala。\n总结：下载kafka安装包，准备java运行环境即可。\n2.解压 额，就是字面意思，解压压缩包就可以了。\nWindows不用教了吧，下个什么7-zip，bandizip之类的解压就可以了。\nlinux命令也不难，\n1 tar -zxvf 压缩包目录 -C 解压目录 解压完我个人的习惯是把解压目录改名成kafka，这个随意不是必须做的。\n3.进行配置 我这次选择在Windows上部署kafka，主流方式是部署在linux上啦，其实都一样的。\n但是部署在linux上一般不需要进行下面的配置：\n先建一个文件夹用来存放kafka的日志。\n然后进入kafka\\config用vim或记事本打开里面的server.properties。\n找到62行\nlog.dirs=/tmp/kafka-logs\n这是日志文件的地址，很显然这不是Windows文件系统应该有的地址。\n现在换成你刚刚建的文件夹的位置。\n但是注意，要把路径的单斜杠\\重复一遍进行转义，即把\\换成 \\\\\n接下来的步骤，不管部署在Windows还是linux上都要进行处理。\n找到34行\nlisteners=PLAINTEXT://:9092\n这是是kafka的地址，改成\n1 listeners=PLAINTEXT://localhost:9092 这样kafka就会监听本地9092端口了。\n这是我配置完之后的配置文件，可以给你参考。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 # Licensed to the Apache Software Foundation (ASF) under one or more # contributor license agreements. See the NOTICE file distributed with # this work for additional information regarding copyright ownership. # The ASF licenses this file to You under the Apache License, Version 2.0 # (the \u0026#34;License\u0026#34;); you may not use this file except in compliance with # the License. You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # This configuration file is intended for use in ZK-based mode, where Apache ZooKeeper is required. # See kafka.server.KafkaConfig for additional details and defaults # ############################# Server Basics ############################# # The id of the broker. This must be set to a unique integer for each broker. broker.id=0 ############################# Socket Server Settings ############################# # The address the socket server listens on. If not configured, the host name will be equal to the value of # java.net.InetAddress.getCanonicalHostName(), with PLAINTEXT listener name, and port 9092. # FORMAT: # listeners = listener_name://host_name:port # EXAMPLE: # listeners = PLAINTEXT://your.host.name:9092 #listeners=PLAINTEXT://:9092 listeners=PLAINTEXT://localhost:9092 # Listener name, hostname and port the broker will advertise to clients. # If not set, it uses the value for \u0026#34;listeners\u0026#34;. #advertised.listeners=PLAINTEXT://your.host.name:9092 # Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details #listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL # The number of threads that the server uses for receiving requests from the network and sending responses to the network num.network.threads=3 # The number of threads that the server uses for processing requests, which may include disk I/O num.io.threads=8 # The send buffer (SO_SNDBUF) used by the socket server socket.send.buffer.bytes=102400 # The receive buffer (SO_RCVBUF) used by the socket server socket.receive.buffer.bytes=102400 # The maximum size of a request that the socket server will accept (protection against OOM) socket.request.max.bytes=104857600 ############################# Log Basics ############################# # A comma separated list of directories under which to store log files log.dirs=D:\\\\softwareLocate\\\\kafka\\\\logs # The default number of log partitions per topic. More partitions allow greater # parallelism for consumption, but this will also result in more files across # the brokers. num.partitions=1 # The number of threads per data directory to be used for log recovery at startup and flushing at shutdown. # This value is recommended to be increased for installations with data dirs located in RAID array. num.recovery.threads.per.data.dir=1 ############################# Internal Topic Settings ############################# # The replication factor for the group metadata internal topics \u0026#34;__consumer_offsets\u0026#34; and \u0026#34;__transaction_state\u0026#34; # For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3. offsets.topic.replication.factor=1 transaction.state.log.replication.factor=1 transaction.state.log.min.isr=1 ############################# Log Flush Policy ############################# # Messages are immediately written to the filesystem but by default we only fsync() to sync # the OS cache lazily. The following configurations control the flush of data to disk. # There are a few important trade-offs here: # 1. Durability: Unflushed data may be lost if you are not using replication. # 2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush. # 3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks. # The settings below allow one to configure the flush policy to flush data after a period of time or # every N messages (or both). This can be done globally and overridden on a per-topic basis. # The number of messages to accept before forcing a flush of data to disk #log.flush.interval.messages=10000 # The maximum amount of time a message can sit in a log before we force a flush #log.flush.interval.ms=1000 ############################# Log Retention Policy ############################# # The following configurations control the disposal of log segments. The policy can # be set to delete segments after a period of time, or after a given size has accumulated. # A segment will be deleted whenever *either* of these criteria are met. Deletion always happens # from the end of the log. # The minimum age of a log file to be eligible for deletion due to age log.retention.hours=168 # A size-based retention policy for logs. Segments are pruned from the log unless the remaining # segments drop below log.retention.bytes. Functions independently of log.retention.hours. #log.retention.bytes=1073741824 # The maximum size of a log segment file. When this size is reached a new log segment will be created. #log.segment.bytes=1073741824 # The interval at which log segments are checked to see if they can be deleted according # to the retention policies log.retention.check.interval.ms=300000 ############################# Zookeeper ############################# # Zookeeper connection string (see zookeeper docs for details). # This is a comma separated host:port pairs, each corresponding to a zk # server. e.g. \u0026#34;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002\u0026#34;. # You can also append an optional chroot string to the urls to specify the # root directory for all kafka znodes. zookeeper.connect=localhost:2181 # Timeout in ms for connecting to zookeeper zookeeper.connection.timeout.ms=18000 ############################# Group Coordinator Settings ############################# # The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance. # The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms. # The default value for this is 3 seconds. # We override this to 0 here as it makes for a better out-of-the-box experience for development and testing. # However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup. group.initial.rebalance.delay.ms=0 4.安装zookeeper 接下来，似乎可以直接启动kafka了，但是你想得美嘞。\n再次重复一下kafka的地位，大数据场景下常用的分布式基于消息订阅模型的开源流处理平台，\n这意味着kafka需要zookeeper提供分布式协调服务，协调各个kafka集群中的机器，虽然我们只是在安装单机开发测试服务器，但是zookeeper还是少不了。\n前往zookeeper官网，下载安装包，你划到下面就可以看到\nDownload\nApache ZooKeeper 3.9.3 is our current release, and 3.8.4 our latest stable release.\nApache ZooKeeper 3.9.3\nApache ZooKeeper 3.9.3(asc, sha512)\nApache ZooKeeper 3.9.3 Source Release(asc, sha512)\n在这里，我选择下载zookeeper 3.9.3\n点击Apache ZooKeeper 3.9.3(asc, sha512)这个链接就可以了。\nWe suggest the following location for your download:\nhttps://dlcdn.apache.org/zookeeper/zookeeper-3.9.3/apache-zookeeper-3.9.3-bin.tar.gz\nAlternate download locations are suggested below.\nIt is essential that you verify the integrity of the downloaded file using the PGP signature ( .asc file) or a hash ( .md5 or .sha* file).\n然后你会看到这样的页面，点击上面的链接，https://dlcdn.apache.org/zookeeper/zookeeper-3.9.3/apache-zookeeper-3.9.3-bin.tar.gz就可以下载到zookeeper安装包了。\n然后找个地方解压就可以了。\n再对zookeeper进行配置，应该轻车熟路了。\n进入zookeeper\\conf找到zoo.cfg用vim或记事本打开，\n直接给你看我的配置文件，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # The number of milliseconds of each tick tickTime=2000 # The number of ticks that the initial # synchronization phase can take initLimit=10 # The number of ticks that can pass between # sending a request and getting an acknowledgement syncLimit=5 # the directory where the snapshot is stored. # do not use /tmp for storage, /tmp here is just # example sakes. dataDir=D:\\\\softwareLocate\\\\zookeeper\\\\data dataLogDir=D:\\\\softwareLocate\\\\zookeeper\\\\log # the port at which the clients will connect clientPort=2181 # the maximum number of client connections. # increase this if you need to handle more clients #maxClientCnxns=60 # # Be sure to read the maintenance section of the # administrator guide before turning on autopurge. # # https://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance # # The number of snapshots to retain in dataDir #autopurge.snapRetainCount=3 # Purge task interval in hours # Set to \u0026#34;0\u0026#34; to disable auto purge feature #autopurge.purgeInterval=1 ## Metrics Providers # # https://prometheus.io Metrics Exporter #metricsProvider.className=org.apache.zookeeper.metrics.prometheus.PrometheusMetricsProvider #metricsProvider.httpHost=0.0.0.0 #metricsProvider.httpPort=7000 #metricsProvider.exportJvmInfo=true 你要配置的是12和13行，配置zookeeper数据文件夹和zookeeper日志文件夹，找个地方新建出这两个文件夹然后把路径换成你自己的即可。\ndataDir=D:\\\\softwareLocate\\\\zookeeper\\\\data dataLogDir=D:\\\\softwareLocate\\\\zookeeper\\\\log\n5.启动zookeeper 接下来，我们终于可以启动zookeeper和kafka了。\n我们要先启动zookeeper。\n进入zookeeper\\bin文件夹，找到zkServer.cmd（对linux系统，找到zkServer.sh），然后打开cmd等终端。\n如果你不知道怎么打开终端的话，对linux你还能不知道也是神人了。\n对于Windows系统，你去文件资源管理器的地址栏，输入cmd回车即可。\n在终端中输入zkServer.cmd的文件名再按回车\n1 zkServer.cmd 就可以启动zookeeper了。\n6.启动kafka 然后我们来启动kafka。\n启动kafka就是启动\nkafka\\bin\\windows\\kafka-server-start.bat\n但是我们还得指定刚刚设置的配置文件，所以我的建议是你去kafka\\bin目录，打开cmd输入\n1 bin\\windows\\kafka-server-start.bat config\\server.properties 并按回车。\n解析一下这个命令，命令的前一半是指定到了当前目录下的bin目录下的windows里面的kafka-server-start.bat文件。\n后一半类似，指定了我们刚刚书写的配置文件。\n只需要稍等片刻，kafka就会启动完成了。\n7.跑一个小demo 这里我选择复用smartCanvas项目的代码，\n由于这是一个spring boot项目所以这里选择使用spring-kafka来操作kafka。\n首先安装依赖：\n1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.kafka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-kafka\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 然后前往application.yml进行设置。例如：\n1 2 3 4 5 6 7 8 9 10 11 12 spring: kafka: bootstrap-servers: \u0026#34;kafka服务器地址\u0026#34; producer: # 消息生产者key和value序列化器，这里是字符串序列化器 key-serializer: org.apache.kafka.common.serialization.StringSerializer value-serializer: org.apache.kafka.common.serialization.StringSerializer # 类似地，这里是消费者key和value序列化器 consumer: key-deserializer: org.apache.kafka.common.serialization.StringDeserializer value-deserializer: org.apache.kafka.common.serialization.StringDeserializer group-id: \u0026#34;使用者组名称\u0026#34; 然后在消息生产者处注入kafkaTemplate操作kafka。\n1 2 @Resource private KafkaTemplate\u0026lt;String, String\u0026gt; kafkaTemplate; 然后将消息发送出去。\n1 kafkaTemplate.send(\u0026#34;smartCanvas_genChartByAI\u0026#34;, JSONUtil.toJsonStr(chart)); 这里的\u0026quot;smartCanvas_genChartByAI\u0026quot;是kafka中的话题（topic）的名称。\nJSONUtil.toJsonStr(chart)是一个字符串，这个就是消息生产者产生的消息。\n消息生产者代码示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 @Resource private ChartService chartService; //接口依赖的其他服务 @Resource private UserService userService; //接口依赖的其他服务 @Resource private AiService aiService; //接口依赖的其他服务 @Resource private RedissonUtils redissonUtils; //接口依赖的其他服务 @Resource private KafkaTemplate\u0026lt;String, String\u0026gt; kafkaTemplate; /** * 智能分析（异步） * * @param file 上传的文件 * @param requestDTO 智能分析请求 * @param request 请求 * @return 智能分析结果 */ @PostMapping(\u0026#34;/gen/async\u0026#34;) public BaseResponse\u0026lt;GenResultVO\u0026gt; genChartAsyncByAi(@RequestPart(\u0026#34;file\u0026#34;) MultipartFile file, GenChartByAiRequest requestDTO, HttpServletRequest request) { chartService.validGenChartParams(file, requestDTO); User user = userService.getLoginUser(request); try { redissonUtils.limitRate(\u0026#34;smartCanvas_genChartByAI_async_\u0026#34; + user.getId(), 2L); } catch (BusinessException e) { throw new BusinessException(ErrorCode.TOO_MANY_REQUESTS_ERROR, \u0026#34;请求过于频繁，请稍后再试\u0026#34;); } String data = ExcelUtils.excelToCsv(file); Chart chart = Chart.builder() .chartData(data) .chartName(requestDTO.getChartName()) .chartType(requestDTO.getChartType()) .goal(requestDTO.getGoal()) .createrId(user.getId()) .status(ChartStatusEnums.PROCESSING.getValue()) .execmsg(ChartStatusEnums.PROCESSING.getDesc()) .build(); chartService.save(chart); //提交给kafka消息队列 kafkaTemplate.send(\u0026#34;smartCanvas_genChartByAI\u0026#34;, JSONUtil.toJsonStr(chart)); return ResultUtils.success(new GenResultVO(null, \u0026#34;\u0026#34;, \u0026#34;{}\u0026#34;, ChartStatusEnums.PROCESSING.getValue(), ChartStatusEnums.PROCESSING.getDesc())); } 然后是消息的消费者，\n只需要给消息的消费者方法增加注解@KafkaListener(topics = {\u0026quot;要接受消息的topic名称\u0026quot;})即可。\n在smartCanvas中是这样实现的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 package cn.cola.smartcanvas.service.impl; import cn.cola.smartcanvas.model.enums.ChartStatusEnums; import cn.cola.smartcanvas.model.po.Chart; import cn.cola.smartcanvas.model.vo.GenResultVO; import cn.cola.smartcanvas.service.AiService; import cn.cola.smartcanvas.service.ChartService; import cn.cola.smartcanvas.service.KafkaService; import cn.hutool.json.JSONUtil; import lombok.extern.slf4j.Slf4j; import org.apache.kafka.clients.consumer.ConsumerRecord; import org.springframework.kafka.annotation.KafkaListener; import org.springframework.stereotype.Service; import javax.annotation.Resource; /** * 卡夫卡服务实现类 * * @author ColaBlack */ @Service @Slf4j public class KafkaServiceImpl implements KafkaService { @Resource private AiService aiService; @Resource private ChartService chartService; /** * 智能分析任务 * * @param record 消息记录 */ @Override @KafkaListener(topics = {\u0026#34;smartCanvas_genChartByAI\u0026#34;}) public void genResultTask(ConsumerRecord\u0026lt;String, String\u0026gt; record) { if (record == null || record.value() == null) { log.error(\u0026#34;kafka 中消息记录为空\u0026#34;); return; } GenResultVO resultVO; Chart chart = JSONUtil.toBean(record.value(), Chart.class); String chartData = chart.getChartData(); String goal = chart.getGoal(); String chartType = chart.getChartType(); if (chartType == null) { chartType = \u0026#34;任意统计图\u0026#34;; } try { resultVO = aiService.genResult(goal, chartType, chartData); resultVO.setId(chart.getId()); } catch (Exception e) { log.error(\u0026#34;智能分析异常\u0026#34;, e); chart.setStatus(ChartStatusEnums.FAILED.getValue()); chart.setExecmsg(ChartStatusEnums.FAILED.getDesc()); chartService.updateById(chart); return; } chart.setGeneratedChart(resultVO.getOption()); chart.setAnalyzedResult(resultVO.getResult()); chart.setStatus(ChartStatusEnums.SUCCESS.getValue()); chart.setExecmsg(ChartStatusEnums.SUCCESS.getDesc()); chartService.updateById(chart); } } @Service注解将消息消费者注册为spring bean，然后genResultTask就是真正的处理消息的方法。\nConsumerRecord\u0026lt;String, String\u0026gt; record的record的value就是消息生产者产生的消息了。\n在smartCanvas项目里，是通过将消息反序列化为java对象再进行下一步业务逻辑处理的。\n1 Chart chart = JSONUtil.toBean(record.value(), Chart.class); ","date":"2024-11-25T20:35:35+08:00","permalink":"https://ColaBlack.github.io/p/windows%E5%A6%82%E4%BD%95%E9%83%A8%E7%BD%B2kafka%E5%92%8Czookeeper/","title":"Windows如何部署kafka和zookeeper"},{"content":"初次发布于我的个人文档。（每次都是个人文档优先发布哦）\n在上次我们以浏览器的事件循环为例简要介绍了如何调度异步资源，这一次要来填个坑，介绍一下浏览器是如何渲染页面的。没看过上一期的话就先看一下上一期的开头，了解一下浏览器的多进程图景。\n1.解析HTML 在上一期我们讲到，浏览器的页面由渲染进程完成，在这一期你将看到渲染进程是一个包含了渲染主线程等多个线程的进程。\n当浏览器通过网络进程向服务器发送请求得到响应的HTML文本后，他要做的第一个工作就是解析收到的HTML文本。\n对于大部分标签，建立对应的DOM树。对于CSS，建立对应的CSSOM树。\n但是当解析工作遇到link的时候，按道理就需要去下载对应的css，但是我们知道网络IO是一个耗时比较长的过程，所以这个步骤也会阻塞渲染主线程。\n因此，浏览器并不是以这个方式解析的。\n而是先启动一个预解析线程，预先快速\u0026quot;浏览\u0026quot;一下HTML标签，下载HTML文本引用的外部CSS文件和JS文件。\n当渲染主线程遇到一般的标签那就解析成DOM，但是当渲染主线程遇到link引用CSS的时候，渲染主线程将不会等待，直接解析下面的其他内容。（异步）\n那么外部的CSS由谁解析呢？\n由和刚刚说的预解析线程解析。\n那外部JS呢？\nJS比较特殊，现在来讲。\n由于在JS中存在改变DOM树和CSSOM树的可能，所以JS的解析完全由渲染主线程操刀，并且当渲染主线程遇到script标签的时候，它会暂停现有的对HTML的解析（阻塞），等待预解析线程把对应的JS代码下载好，并且需要等到全局代码都被解析执行完成之后才继续解析HTML文本。\n总之，解析过程就是得到DOM和CSSOM的过程，此时的CSSOM已经是一个包含浏览器默认样式、内部样式、外部样式、行内样式的比较完整的树结构了。\n2.样式计算 之所以说是“比较完成的树”是因为此时CSSOM里还保留着em等相对值和计算属性，这一步就是将这些相对值和计算属性计算出来。\n计算之后的就是最终样式computed style了。\n非常简单，不需要多说什么其他话了。\n3.布局 第三步是根据前面的信息对页面进行布局，生成布局树。\n在这一步渲染主线程要遍历全部的DOM，计算他们的位置信息和几何信息。\n但是注意，布局树和DOM树并不完全一致。\n对于CSS为display:none的元素，由于他们不显示，所以不会在布局树中。DOM中不存在伪元素节点，但我们知道伪元素节点都有几何信息所以他们存在于布局树中。\n由于存在规定\n内容必须在行盒中\n行盒和块盒不能相邻\n所以，在布局这一步还会生成一些匿名的行盒或者块盒来使得页面满足这一规则。\n4.分层 接下来，渲染主线程会对布局树的元素进行分层。这是一个优化的方法，当将来某一层改变后就只需要对这一层的元素进行对应改变就可以了，这将提高浏览器的性能。\n5.绘制 接下来，绘制这一步就是为每一层生成对应的绘制指令，你可以理解为canvas之类的东西。\n啊，什么把画笔移动到哪里哪里，然后向哪里哪里花一条直线什么的。\n到生成绘制指令这一步，渲染主线程的任务才算结束。\n6.分块 接下来压力给到了合成线程。啊，其实也不全是。\n分块的工作要交给很多个被称为分块器的线程协作完成。\n所谓分块就是字面意思，将每一层的元素分为若干小块，以便后续步骤的分工。\n7.光栅化 一看到光栅化这个词已经有人在瑟瑟发抖了吧，其实很简单的。\n就是把前面分的每一块变成位图。\n或者说，合成线程会将每一个块的信息交给显卡（GPU）进程来绘制我们真正能看到的图像。\n当然GPU进程会开多个线程来同时绘制图像，并且它将优先计算靠近视口的块，因为用户正在看那里嘛。\n8.绘制 这一步是最后一步了。\n合成线程在拿到GPU渲染的一张张位图后，将生成指引（quad）信息，标注出每个位图应该画在屏幕的哪个位置，要不要进行选择和缩放等。\nCSS中的transform正是也只是作用于这一阶段，这也是其运行效率高的本质原因。\n当生成指引信息后，合成线程会将指引信息传递给GPU进程，然后GPU进程会产生系统调用操作显卡硬件绘制用户真正能看到的页面图像。\n9.后记 这就是浏览器渲染一个页面的全部步骤了。\n了解这个或许没有什么用，额可能吧。\n不过可以让你小心一点。\n有一些操作会影响布局树，这时浏览器会从第三步重新开始后面的全部过程了，这被称为回流/重排(reflow)，如果可以的话应该尽量避免这样的操作。\n当然，当你连续多次进行修改布局树的操作，浏览器会进行优化，自动合并这些操作，等对应的JavaScript代码全部完成后才统一进行一次reflow。\n但是这也意味着，这时JavaScript获取的布局属性可能是不准确的，为了避免这种情况，当JavaScript代码尝试获取布局属性的时候浏览器会立刻进行reflow操作而不是等待代码全部运行完成。所以这种情况也应该规避。\n而当你改变了DOM的几何信息的时候，浏览器就需要从绘制这一步重新开始，这一过程被称为重绘(repaint)。\n这个效率会比reflow高一些，因为reflow是从第三步布局开始，也会经历完repaint经历的全部过程。（也有说法称reflow会引起repaint，从结果上看两种说法没有任何区别，你怎么理解都可以）\n但是还得是transform高效啊，只影响了最后一步绘制，只有合成线程受到影响了而已，这效率高的不是一点半点啊。\n","date":"2024-11-23T16:28:26+08:00","permalink":"https://ColaBlack.github.io/p/%E6%B5%8F%E8%A7%88%E5%99%A8%E6%98%AF%E5%A6%82%E4%BD%95%E6%B8%B2%E6%9F%93%E9%A1%B5%E9%9D%A2%E7%9A%84/","title":"浏览器是如何渲染页面的"},{"content":"初次发布于我的个人文档\n参考:\nchromiun官方文档\nw3c官方文档\n针对一个异步的程序应该如何对它进行资源的调度呢？本文以浏览器为典型范例进行简单介绍。\n1.查看浏览器的多进程图景 打开任意一个浏览器这里以edge为例。\n然后打开Windows的任务管理器，你看到的可能是这样：\n事实上，在edge浏览器（其他浏览器也有类似的功能）按shift+esc键能打开浏览器内部的任务管理器，可能长这样：\n不管怎么样总之，都可以看到你打开了一个浏览器实际上打开了好多个“进行中的程序”也就是进程。\n浏览器作为及其复杂的而又非常常用的程序，不得不使用多进程的方式优化。\n而正是因为浏览器使用了多进程，所以有的时候你会发现，某一个网页卡了但是浏览器没有卡死，一个页面卡死了但是另一个页面没有卡死。这是因为他们本来就“不是一个程序”。\n多进程是一种充分利用计算机硬件资源的方式，关于多进程、多线程和协程的有关概念以后有时间也许会分享。\n总而言之言而总之，浏览器是一个多进程的复杂的应用程序。\n浏览器的诸多线程里，最主要的是三个：\n浏览器进程负责浏览器界面的展示（不是网页，而是浏览器界面内的什么选项卡啊按钮啊什么的）、用户交互、子进程管理等等\n网络进程负责启动多个线程来执行网络任务，也就是收发各种网络请求。\n渲染进程才是负责网页渲染的，有时间也会展开说说浏览器是如何渲染网页的。 渲染进程是浏览器最重要也是最繁忙的进程，说他重要是因为我打开浏览器最主要的就是想看页面啊，没渲染进程怎么能行？说他繁忙，可以等以后展开。\n2.阻塞和非阻塞、同步和异步 刚刚我们说渲染进程是浏览器最重要也是最繁忙的进程，那么渲染进程是怎么组织资源调度和分配的呢？\n比如说，用户点击了一个按钮，我肯定要执行一段代码，但是与此同时可能有一个计时器也刚好到时间了，也想执行一段代码，那怎么办呢？\n进一步的，我怎么知道用户点击了一个按钮呢？是不是我得一直监听用户输入啊，那我岂不是要开一个任务一直运行着，那我渲染进程岂不是还得等用户点击按钮用户有输入了才能继续执行？\n这种现象被称为阻塞。\n也就是这个任务会卡着某一个线程，这个线程要等这个任务完成才能继续执行代码。\n我们写的一般的代码是不会卡着线程的，比如什么i++啊之类的，一下子就完成了所以不会阻塞。\n那如果我想做一些网络交互啊，磁盘输入输出（input/output,IO)之类的，那时间就长了，主线程就得等这些任务完成才能继续执行了，这就是阻塞了。\n再比如，下面的Python代码\n1 2 3 a = \u0026#34;hello World\u0026#34; input(\u0026#34;请输入\u0026#34;) print(a) 第二行在等待用户输入，如果用户一直不输入那么程序不会停止也不会运行第三个语句，而是会一直等待用户输入，用术语来讲就是阻塞。\n像这种，每个任务都按顺序完成的情况我们称之为同步。\n根据刚刚举的例子可以发现，同步的代码可能发生阻塞也可能不发生，我们分别称这两种情况为同步阻塞、同步非阻塞。\n结论：同步不一定阻塞\n不过比起这个结论更重要的是理解刚刚说的分析的过程。\n对于浏览器来说，他确实想执行监听用户的任务，但是又不想阻塞主线程不然用户看到的网页就一卡一卡的。\n那该怎么办呢？\n那就要使用异步的方式。\n这是一个简单的用java(python由于全局解释器锁的存在不太适合当例子了，JavaScript则是运行在浏览器的渲染主线程上也不太适合)实现的异步调用demo。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 public class CallbackThreadExample { // 定义一个回调接口 interface Callback { void onFinish(String result); } // 实现Runnable接口的类 static class Task implements Runnable { private final Callback callback; public Task(Callback callback) { this.callback = callback; } @Override public void run() { // 执行一些任务 try { Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } // 任务完成，调用回调函数 if (callback != null) { callback.onFinish(\u0026#34;任务完成\u0026#34;); } } } public static void main(String[] args) { // 创建一个回调对象 Callback callback = result -\u0026gt; System.out.println(\u0026#34;回调函数被调用，结果：\u0026#34; + result); // 创建并启动新线程 Thread thread = new Thread(new Task(callback)); thread.start(); // 主线程可以继续执行其他任务 System.out.println(\u0026#34;主线程继续执行...\u0026#34;); } } callback被称为回调函数，简单说就是“回头再调用\u0026quot;。\nmain函数里定义了回调函数 Callback callback = result -\u0026gt; System.out.println(\u0026quot;回调函数被调用，结果：\u0026quot; + result);\n就是说等时机成熟，你给我调用这句输出语句。\ntask类定义了一个任务，叫线程睡眠2秒，然后再调用回调函数。（你看，回调函数是不是“回头再调用了”）\n很显然，task任务会阻塞主线程2秒，我们不希望这件事发生。所以新开了另一个线程来执行这个任务，这样主线程就可以继续执行了，也就不会阻塞了。\n这就是异步非阻塞。\n创建新线程执行原本会阻塞的任务，利用回调函数给予反馈是异步的一种实现方式。前面我们说同步的程序所有任务会按顺序完成，但这里异步的任务会和主线程同时完成，这就是异步和同步的区别。\n3.消息队列 那么浏览器是怎么处理纷繁复杂的异步任务的呢？\n熟悉JavaScript的话你会发现，像网络IO，交互，计时器等都是也只能按异步+回调的方式调用。那浏览器会在什么时候执行回调呢？\n如果网络IO完成的同时，计时器时间也到了应该先完成哪个？\n很快你会发现，这是一个任务生产的速率大于任务消费的速率的情况，这种模型我们一般可以通过排队的方式解决。\n你们俩同时想我启用某个任务了是吧，一个任务正在进行另外两个任务也想启动是吧，排队！\n队列这种数据结构就是现实里的排队，讲究的是先到先得。\n在我们这种情况下，用面向对象的术语来说就是需要一个消息队列，当一个任务想执行了，先往消息队列里发一个消息，我想执行某某任务，然后渲染主线程会先服务队首也就是排在最前面的人。\n4.事件循环 在浏览器具体实现的时候，又有一些细节需要注意。\n我们以谷歌chromiun内核为例，观察chromiun的源码，你会发现在chromiun渲染进程中存在一个死循环（这个循环被W3C称为事件循环在chromiun源码中被称为消息循环)，它不断地从消息队列中取任务，当消息队列为空时会休眠，只要队列里有任务就执行队首的任务，是吗？\n是也不完全是。\n对于一般的简单程序来说也许这样就足够了，但是对浏览器这个复杂的应用程序来说，完全不够！\n浏览器中有事件交互、网络IO等诸多异步任务，很显然事件交互的优先级要高一些，也就是当用户点击按钮啊什么的你浏览器必须尽快给出响应，不要让用户觉得卡顿。\n但是这样的话就破坏了消息队列“先进先出，先到先得”的特性，又该怎么办呢？\n5.微队列和宏队列 动动你的脑瓜子想想，虽然队列里的成员不能有优先级，只能先到先得，但是消息队列不是可以有优先级吗？\n我开好几个不同优先级的消息队列不就得了。\n如果你看过很多早期的教程或者早期w3c规范，你可能会听说过微队列和宏队列的说法，但是随着浏览器执行任务的复杂，w3c已经不再使用宏队列的说法了。（微队列仍在使用）光靠微队列和宏队列已经不足以支撑现代浏览器的资源调度了。\n现代浏览器有微队列、交互队列、延时队列等诸多消息队列。\n按照w3c最新的规范，微队列是优先级最高的队列，当渲染主进程完成手头现有的工作后只要微队列有任务在等着，那么他就会执行微队列的任务。这是因为微队列里都是一些支撑浏览器运行的重要任务。交互队列由于和用户体验息息相关所以优先级也比较高。像延时队列这种只关乎计时器的消息队列优先级就比较低，如果微队列的任务和交互队列的任务没有完成，那即使计时器到了，计时器的回调函数也不会被执行。这也是为什么计时器其实不能严格准确精准无误地按照程序员设定的时间执行任务。\n前面我们说“微队列里都是一些支撑浏览器运行的重要任务”其实也并不完全吧，我们还是有办法把一个函数添加到微队列的，可以通过以下代码\n1 Promise.resolve().then(函数) 将函数包装成任务，塞到微队列。\n翻看chromiun内核源码你会知道，这些消息队列里存放的不是函数句柄（或者说指向函数的指针）而是一个被包装起来的结构体，所以这里要用“包装成任务”的说法。\n","date":"2024-11-15T21:07:57+08:00","permalink":"https://ColaBlack.github.io/p/%E5%BC%82%E6%AD%A5%E4%B8%8E%E8%B5%84%E6%BA%90%E8%B0%83%E5%BA%A6-%E4%BB%A5%E6%B5%8F%E8%A7%88%E5%99%A8%E4%BA%8B%E4%BB%B6%E5%BE%AA%E7%8E%AF%E4%B8%BA%E4%BE%8B/","title":"异步与资源调度 以浏览器事件循环为例"},{"content":"初次发布于我的个人文档\n1.安装 使用如下的命令之一就可以获取工程费的phaser项目。\n1 2 3 4 5 npm create @phaserjs/game@latest npx @phaserjs/create-game@latest yarn create @phaserjs/game pnpm create @phaserjs/game@latest bun create @phaserjs/game@latest 或者使用\n1 npm install phaser 安装npm包在其他项目使用。\n也可以使用\n1 2 3 4 \u0026lt;script src=\u0026#34;//cdn.jsdelivr.net/npm/phaser@3.86.0/dist/phaser.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;//cdn.jsdelivr.net/npm/phaser@3.86.0/dist/phaser.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://cdnjs.cloudflare.com/ajax/libs/phaser/3.86.0/phaser.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://cdnjs.cloudflare.com/ajax/libs/phaser/3.86.0/phaser.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 这些方式从cdn获取源码。\n或者，按照本文的方式，从github直接下载源码在本地使用。\n前往其github仓库下载dist目录下的phaser.js然后导入自己的项目中。\n例如\n1 \u0026lt;script src=\u0026#34;js/phaser.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 2.预加载资源 接下来以本人模仿的玩具项目google-dinosaur为例介绍如何使用phaser.js制作简单的小游戏。\n首先需要先创建一个游戏场景类，在构造函数中声明场景的名称。\n1 2 3 4 5 export default class PreLoad extends Phaser.Scene { constructor() { super(\u0026#34;preLoadScene\u0026#34;); } } 当进入场景时phaser.js会先调用场景的preload方法。\n在preload方法中调用以下两个函数就可以预加载音乐和图片资源。\n1 2 this.load.audio(\u0026#34;音乐名称\u0026#34;, \u0026#34;音乐地址\u0026#34;); this.load.image(\u0026#34;图片名称\u0026#34;, \u0026#34;图片地址\u0026#34;); 而对于动画，我们只需要提供几个关键帧的图片，phaser.js会自动绘制动画，这种我们称之为精灵表单对象。使用这样的方法载入：\n1 2 3 4 5 this.load.spritesheet( \u0026#34;关键帧的名称\u0026#34;, \u0026#34;关键帧的地址\u0026#34;, {关键帧信息，如关键帧的大小等} ); 接下来phaser.js会调用create方法创建场景，在google-dinosaur项目中，create方法用于跳转到gameScene场景。\n1 this.scene.start(\u0026#34;gameScene\u0026#34;); 最后，给一下第一个场景的完整代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 /** * 在游戏开始前预加载资源 */ export default class PreLoad extends Phaser.Scene { constructor() { super(\u0026#34;preLoadScene\u0026#34;); } preload() { // 加载背景音乐 // 死亡音效 this.load.audio(\u0026#34;dead\u0026#34;, \u0026#34;./assets/audio/Dead.wav\u0026#34;); // 跳跃音效 this.load.audio(\u0026#34;jump\u0026#34;, \u0026#34;./assets/audio/Jump.wav\u0026#34;); // 得分音效 this.load.audio(\u0026#34;score\u0026#34;, \u0026#34;./assets/audio/Score.wav\u0026#34;); // 加载图片资源 for (let i = 1; i \u0026lt;= 5; i++) { // 5张仙人掌图片 this.load.image(`cactus-${i}`, `./assets/images/Cactus-${i}.png`); } // 地面图片 this.load.image(\u0026#34;ground\u0026#34;, \u0026#34;./assets/images/Ground.png\u0026#34;); // 游戏结束文字图片 this.load.image(\u0026#34;gameover_text\u0026#34;, \u0026#34;./assets/images/Gameover_text.png\u0026#34;); // 再玩一次按钮图片 this.load.image(\u0026#34;replay_button\u0026#34;, \u0026#34;./assets/images/Replay_button.png\u0026#34;); for (let i = 1; i \u0026lt;= 4; i++) { // 4张小恐龙图片 this.load.spritesheet( `dinosaur-${i}`, `./assets/images/Dinosaur-${i}.png`, { frameWidth: 88, frameHeight: 94 } ); } } create() { // 切换到游戏场景 this.scene.start(\u0026#34;gameScene\u0026#34;); } } 3.创建场景 在介绍如何创建场景前，我们先写gameScene场景的代码框架，也就是\n1 2 3 4 5 export default class GameScene extends Phaser.Scene { constructor() { super(\u0026#34;gameScene\u0026#34;); } } 由于资源已经在前面预加载完了所以这里不需要预加载资源，我们直接写create方法即可。\n3.1创建游戏对象 在创建场景的时候主要的代码是创建游戏需要的对象，以google-dinosaur项目为例，需要创建地面、小恐龙、仙人掌等对象。\n地面的宽度和游戏画布的宽度一样，高度则位与中间，这意味着我们要先获取画布的高度和宽度。\n1 2 3 // 获取游戏画布的宽度和高度 this.width = this.sys.game.config.width; this.height = this.sys.game.config.height; 地面是静态不动的，对于这种静态的对象要用this.physics.add.staticGroup()方法先创建静态对象组。\n然后创建对象\n1 2 3 4 this.ground .create(this.width / 2, this.height - 13, \u0026#34;ground\u0026#34;) .setScale(2) .refreshBody(); create方法的前两个参数是对象的坐标，在phaser.js中默认的坐标系是从左上角开始,越往右x越大，越往下y越大。（当然，这个是可以自己改的）而这里的坐标默认是以对象的左上角为标准的。(左上角也被称为原点，也是可以自己改动的)\n例如你想把一个图片的左上角放到(0,0)，那就直接在create里输入0,0就可以了。\n\u0026ldquo;ground\u0026quot;是刚刚预加载的图片对象的名字，有这个参数phaser.js才知道刚刚创建的地面对象的贴图是ground。\nsetScale(2)则是将地面放大了2倍,refreshBody()要求phaser.js重新计算刷新地面对象的物理属性。\n对于会运动且有物理碰撞效果的一般的对象，可以用this.physics.add.group()为他们创造组。\n针对精灵表单和其他的一般对象可以用这样的方式创建\n1 2 3 this.dinosaur = this.physics.add .sprite(50, this.height / 2, \u0026#34;dinosaur-1\u0026#34;) .setOrigin(0, 1); dinosaur-1是动画的第一帧或者是对象的贴图。setOrigin则将该对象的原点设置到了x为0%，y为100%也就是对象的左下角了。\n如果要加入碰撞效果呢，就可以用这样的方法\n1 2 // 让小恐龙与地面发生碰撞，防止小恐龙掉落 this.physics.add.collider(this.dinosaur, this.ground); 3.2初始化动画 参考google-dinosaur的代码，\n1 2 3 4 5 6 7 8 9 10 11 12 // 定义恐龙奔跑的动画 this.dinosaur.anims.create({ key: \u0026#34;run\u0026#34;, frames: [ { key: \u0026#34;dinosaur-1\u0026#34; }, { key: \u0026#34;dinosaur-2\u0026#34; }, { key: \u0026#34;dinosaur-3\u0026#34; }, { key: \u0026#34;dinosaur-4\u0026#34; }, ], frameRate: 10, repeat: -1, }); 精灵表单的anims.create方法可以初始化动画，key则给了动画一个名字，叫做run。frames数组则列举了动画需要的关键帧的名字。frameRate是帧速率，repeat则说明了动画需要重复几次，-1表示动画要一直重复。\n3.3初始化音乐 初始化音乐就更简单了。使用this.sound.add(\u0026quot;音乐名称\u0026quot;)就可以了。\n以google-dinosaur为例只要这样就能初始化三个音乐了。\n1 2 3 this.deadSound = this.sound.add(\u0026#34;dead\u0026#34;); this.jumpSound = this.sound.add(\u0026#34;jump\u0026#34;); this.scoreSound = this.sound.add(\u0026#34;score\u0026#34;); 3.4监听用户输入 这里以监听用户键盘输入为例，使用\n1 this.input.keyboard.on(\u0026#34;keydown\u0026#34;, this.handleJump.bind(this), this); keydown表示监听用户的任意键盘输入，也就是用户按任意键就调用handleJump方法。\nhandleJump方法的代码很简单，就不说了。\n1 2 3 4 5 6 7 8 9 10 11 handleJump() { // 如果小恐龙不在地面上，则不执行跳跃以避免用户进行二段跳 if (!this.dinosaur.body.onFloor()) { return; } // 跳跃，设置y的速度为-1500像素每秒(负速度的方向向上) this.dinosaur.setVelocityY(-1500); // 播放跳跃音效 this.jumpSound.play(); } 4.编写每一帧的处理 接下来phaser.js会在游戏的每一帧都调用update函数\n这个部分只有播放精灵表单的动画是通用的。\n1 2 // 播放奔跑动画 this.dinosaur.anims.play(\u0026#34;run\u0026#34;, true); 这个语句就可以播放刚刚初始化的小恐龙奔跑动画。\n其他的语句都不是通用的，我就直接放google-dinosaur的源码给各位参考了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 update(time, delta) { // 播放奔跑动画 this.dinosaur.anims.play(\u0026#34;run\u0026#34;, true); // 检测小恐龙是否跳过仙人掌 this.cactusGroup.getChildren().forEach((cactus) =\u0026gt; { // 如果仙人掌的x坐标小于50且未被计分 if (cactus.x \u0026lt; 50 \u0026amp;\u0026amp; !cactus.getData(\u0026#34;scored\u0026#34;)) { // 标记仙人掌为已计分，避免重复计分 cactus.setData(\u0026#34;scored\u0026#34;, true); // 播放得分音效 this.scoreSound.play(); } }); // 定义计时器，每隔1-5秒生成一个仙人掌 this.timer = this.timer || time; const cactusInterval = Phaser.Math.Clamp( 2000 - this.speed * 100, 500, 2000 ); // 最小间隔为500ms，最大间隔为2000ms if (time - this.timer \u0026gt; cactusInterval) { this.summonCactus(); this.timer = time; } } 5.定义对象交互逻辑 接下来需要游戏其实就已经开始进行了，但是我们还没有定义对象之间的关系和结束游戏的方法。\n例如，在google-dinosaur项目中，当小恐龙和仙人掌碰撞的时候应该停止游戏。\n不过这个你可能得回去修改刚刚写的代码，例如修改增加小恐龙和仙人掌碰撞的代码为\n1 2 3 4 5 6 7 8 // 添加小恐龙与仙人掌组之间的碰撞检测 this.physics.add.collider( this.dinosaur, this.cactusGroup, this.handleDinoCactusCollision, null, this ); 这个代码既增加了二者的碰撞，又定义了当二者碰撞的时候调用handleDinoCactusCollision函数。\n这部分其实也没有通用的代码。\n大致上也就这三个代码比较常用\n1 2 3 4 5 6 7 8 // 播放死亡音效 this.deadSound.play(); // 停止物理模拟 this.physics.pause(); // 停止所有动画 this.anims.pauseAll(); 为了处理google-dinosaur的特殊需求，在该项目里这个函数其实是这样的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 handleDinoCactusCollision(dinosaur, cactus) { // 播放死亡音效 this.deadSound.play(); // 停止物理模拟 this.physics.pause(); // 停止所有动画 this.anims.pauseAll(); this.speed = 1; this.score = 0; // 游戏结束时停止得分增加 if (this.scoreEvent) { this.scoreEvent.remove(false); } this.handleGameOver(); } handleGameOver() { // 显示游戏结束文字 const gameOverText = this.add .image(this.width / 2, this.height / 2 - 100, \u0026#34;gameover_text\u0026#34;) .setScale(2); // 显示再玩一次按钮 const replayButton = this.add .image(this.width / 2, this.height / 2 + 100, \u0026#34;replay_button\u0026#34;) .setInteractive() .setScale(2); // 为再玩一次按钮添加点击事件监听器 replayButton.on(\u0026#34;pointerdown\u0026#34;, () =\u0026gt; { this.scene.restart(); // 重新开始当前场景 }); } 6.配置并启动游戏 通过前面的步骤你已经完成了绝大部分代码。接下来只需要配置一下然后就可以启动游戏啦。\n前面的代码就只是定义了两个类，除了一堆定义之外其实没有代码被执行。\n如果想真正地启动游戏，只需要一句话：\n1 2 // 创建游戏实例 const game = new Phaser.Game(config); config是游戏的配置对象，这里以google-dinosaur项目的配置为例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // 游戏配置 const config = { type: Phaser.AUTO, // 游戏渲染器类型 width: 800,// 游戏画布宽度 height: 300,// 游戏画布高度 backgroundColor: \u0026#34;#ffffff\u0026#34;, //修改背景色为白色 parent: \u0026#34;game\u0026#34;, // 游戏绑定的父标签的id scene: [PreLoad, GameScene], // 游戏场景列表，会先进入第一个场景 physics: { default: \u0026#34;arcade\u0026#34;, // 默认物理引擎 arcade: { gravity: { y: 5000 }, // 重力设置 debug: false, // 调试模式，开发时使用 }, }, }; 每一个配置项我都写了注释，应该可以直接看懂了。\n在这里，游戏渲染器类型你可能不知道是什么意思，其实就是调整游戏是用webGL渲染还是canvas渲染。一般选自动就可以了。\n","date":"2024-11-14T18:59:45+08:00","permalink":"https://ColaBlack.github.io/p/phaser%E5%BC%80%E5%8F%91%E7%AE%80%E5%8D%95%E7%9A%842d%E5%B0%8F%E6%B8%B8%E6%88%8Fdemo/","title":"Phaser开发简单的2d小游戏demo"},{"content":"初次发布于我的个人文档\n本文简要介绍一下如何实现一个简化版的类vue的响应式。\n1.假装不知道响应式 如果我们不知道vue等响应式框架，那么又该如何手动实现类似的功能呢？\n先来看这么一个简单的页面\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;zh-CN\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;My Program\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1 id=\u0026#34;data1\u0026#34;\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;p id=\u0026#34;data2\u0026#34;\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p id=\u0026#34;data3\u0026#34;\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 现在，如果这里的三个data需要变动，与此同时我们还希望页面进行所谓的“重新渲染”即让页面也跟着数据的变动变化应该怎么做呢？\n首先，要写js代码让这几个标签有内容对吗？\n只需要封装这三个函数即可\n1 2 3 4 5 6 7 8 9 const showData1 = (data) =\u0026gt; { document.getElementById(\u0026#34;data1\u0026#34;).innerHTML = data.data1; }; const showData2 = (data) =\u0026gt; { document.getElementById(\u0026#34;data2\u0026#34;).innerHTML = data.data2; }; const showData3 = (data) =\u0026gt; { document.getElementById(\u0026#34;data3\u0026#34;).innerHTML = data.data3; }; 对于旧数据，只需要调用函数传入即可，例如\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 const showData1 = (data) =\u0026gt; { document.getElementById(\u0026#34;data1\u0026#34;).innerHTML = data.data1; }; const showData2 = (data) =\u0026gt; { document.getElementById(\u0026#34;data2\u0026#34;).innerHTML = data.data2; }; const showData3 = (data) =\u0026gt; { document.getElementById(\u0026#34;data3\u0026#34;).innerHTML = data.data3; }; const data = { data1: \u0026#34;Hello World!\u0026#34;, data2: \u0026#34;This is a paragraph.\u0026#34;, data3: \u0026#34;This is another paragraph.\u0026#34;, }; showData1(data); showData2(data); showData3(data); 但是接下来如果要更改data1，你会发现页面并不会变化，除非你重新调用showData1。\n例如，这段代码就实现了3秒后变化data1并使得页面发生变化。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 const showData1 = (data) =\u0026gt; { document.getElementById(\u0026#34;data1\u0026#34;).innerHTML = data.data1; }; const showData2 = (data) =\u0026gt; { document.getElementById(\u0026#34;data2\u0026#34;).innerHTML = data.data2; }; const showData3 = (data) =\u0026gt; { document.getElementById(\u0026#34;data3\u0026#34;).innerHTML = data.data3; }; const data = { data1: \u0026#34;Hello World!\u0026#34;, data2: \u0026#34;This is a paragraph.\u0026#34;, data3: \u0026#34;This is another paragraph.\u0026#34;, }; showData1(data); showData2(data); showData3(data); setTimeout(() =\u0026gt; { data1 = \u0026#34;Welcome to my program.\u0026#34;; showData1(data1); }, 3000); 2.针对特殊变量实现响应式 所以手动实现响应式的关键，就是在改变变量的时候再次调用showData函数。\n然而每次都手动去调用肯定是很麻烦而且不优雅的。\n很容易想到，只要重载对应变量的set方法就可以了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 const showData1 = (data) =\u0026gt; { document.getElementById(\u0026#34;data1\u0026#34;).innerHTML = data.data1; }; const showData2 = (data) =\u0026gt; { document.getElementById(\u0026#34;data2\u0026#34;).innerHTML = data.data2; }; const showData3 = (data) =\u0026gt; { document.getElementById(\u0026#34;data3\u0026#34;).innerHTML = data.data3; }; const data = { _data1: \u0026#34;Hello World!\u0026#34;, // 使用一个下划线前缀来存储data1实际的值 data2: \u0026#34;This is a paragraph.\u0026#34;, data3: \u0026#34;This is another paragraph.\u0026#34;, }; Object.defineProperty(data, \u0026#34;data1\u0026#34;, { get: function () { return this._data1; // 使用存储的实际值 }, set: function (value) { this._data1 = value; // 更新存储的实际值 showData1(value); // 调用showData1来更新页面上的内容 }, }); showData1(data); showData2(data); showData3(data); setTimeout(() =\u0026gt; { data.data1 = \u0026#34;Welcome to my program.\u0026#34;; // 使用新设置的setter }, 3000); 这样就完成了对data1的封装。\n类似地，可以自己手动完成对data2 data3的封装。\n然而，这并不是什么好的选择，自己动手还是太累了。\n3.尝试封装为一般化工具 所以我们要来尝试封装成一般化的工具！\n我们来手写一个封装或者说观察函数，来观察这个对象，为这个对象的所有字段都重写get和set方法就可以了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 function watch(obj) { for (const key in obj) { let innerValue = obj[key]; Object.defineProperty(obj, key, { get: function () { return innerValue; }, set: function (value) { innerValue = value; }, }); } } 也就是这样。\n但是接下来你会发现，我们不知道应该调用哪些函数了。\n不妨回过头想想，手动实现的时候你是怎么知道要调用showData1这个函数的。\n我们为什么不把三个showData函数全部调用一遍呢？\n是不是因为showData1这个函数使用了data1这个变量啊，或者说就是这个函数调用了data1的get方法。\n所以，我们应该先重写get方法，记录哪个函数使用了get方法。\n那我怎么知道是哪个函数正在使用get方法呢？\n解决方案是，让这个函数使用get方法前手动在全局变量上记录自己，然后get函数访问全局变量获取信息。\n原本我们的调用是\n1 showData1(data); 现在改为\n1 showData1(data); 接着，data1的get方法只需要访问全局变量window.__func就知道谁正在调用get方法了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 function watch(obj) { for (const key in obj) { let innerValue = obj[key]; let funcs = []; Object.defineProperty(obj, key, { get: function () { if (window.__func \u0026amp;\u0026amp;!funcs.includes(window.__func)) { funcs.push(window.__func); } return innerValue; }, set: function (value) { innerValue = value; }, }); } } 这就实现了依赖收集。\n然后呢，在有函数调用set方法的时候，只需要调用funcs里面的所有函数即可，也就是派发更新。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 function watch(obj) { for (const key in obj) { let innerValue = obj[key]; let funcs = []; Object.defineProperty(obj, key, { get: function () { if (window.__func \u0026amp;\u0026amp;!funcs.includes(window.__func)) { funcs.push(window.__func); } return innerValue; }, set: function (value) { for (let i = 0; i \u0026lt; funcs.length; i++) { funcs[i](); } innerValue = value; }, }); } } 4.设计代理 但是，每次在调用get方法前还要自己手动设置全局变量还是太麻烦。如何把这个过程也自动化呢？\n其实我们就是想加强调用了属性get方法的函数的功能，而由于我们做的是通用组件又不好直接修改函数本身。\n这时，可以建一个新的对象或者函数，由它代理，或者说替代我们访问旧的函数或对象。\n例如\n1 2 3 4 5 function runFunc(func) { window.__func = func; func(); window.__func = null; } 以后，用户想调用func就使用runFunc代理，由runFunc替用户访问func。现在只要用户用这个函数访问func并且设置了被watch的对象，那么就实现了响应式了。\n","date":"2024-11-13T20:05:21+08:00","permalink":"https://ColaBlack.github.io/p/%E5%93%8D%E5%BA%94%E5%BC%8F%E5%8E%9F%E7%90%86%E7%AE%80%E5%8C%96/","title":"响应式原理（简化）"},{"content":"初次发布于我的个人文档\n参考：\n1.1Panel 官方文档\n本文介绍一下如何利用1panel部署一个简单的前后端分离项目。\n1,拥有一个Liunx服务器 第一步是购买一个Linux服务器，可以买一台线下真实的机器+公网IP或买一个阿里云、腾讯云、京东云、华为云服务器。\n2.安装1panel 参考1panel官方文档，安装1panel。\n在这里以Ubuntu系统为例，只需运行\n1 curl -sSL https://resource.fit2cloud.com/1panel/package/quick_start.sh -o quick_start.sh \u0026amp;\u0026amp; sudo bash quick_start.sh 即可安装，安装完成后终端上有写1panel的URL和账号名密码。\n3.安装运行环境 在虚拟机中安装java等运行环境。\n然后，可以在1panel中安装项目需要的中间件，如MySQL、minio、redis等。\n4.打包后端项目 先介绍一下如何打包maven项目。\n需要注意的是，你可能会发现在idea的maven菜单里，已经有一个package选项了，然而默认情况下这样打的包是不带项目依赖的。所以这样的jar包不能独立运行。\n但是如果你用的是spring boot项目，则pom.xml中可能已经安装了插件spring-boot-maven-plugin\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;excludes\u0026gt; \u0026lt;exclude\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;/exclude\u0026gt; \u0026lt;/excludes\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; 如果pom.xml有这样的代码则说明maven有插件spring-boot-maven-plugin。\n这时直接在idea的maven菜单运行package选项就得到带依赖的jar包了，可以直接java -jar运行。\n以部署笔者的teaai项目为例，打包后你会在target文件夹下看到teaai-backend-0.0.1-SNAPSHOT.jar，这就是打包后的jar文件，直接运行即可启动后端服务。\n对于非spring boot项目又该如何打包呢？\n需要安装maven-assembly-plugin插件，方法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-assembly-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.0\u0026lt;/version\u0026gt;\u0026lt;!-- 插件版本号 --\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;descriptorRefs\u0026gt; \u0026lt;descriptorRef\u0026gt;jar-with-dependencies\u0026lt;/descriptorRef\u0026gt; \u0026lt;/descriptorRefs\u0026gt; \u0026lt;archive\u0026gt; \u0026lt;manifest\u0026gt; \u0026lt;mainClass\u0026gt;edu.zafu.teaai.MainApplication\u0026lt;/mainClass\u0026gt; \u0026lt;!-- 替换为你的主类的完整类名 --\u0026gt; \u0026lt;/manifest\u0026gt; \u0026lt;/archive\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;single\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 然后再运行package即可。\n对于gradle项目，没有什么太大的区别。\n这里只介绍一般的gradle项目如何打带依赖的jar包。\ngradle依赖打包需要安装shadow插件，在build.gradle.kts中的plugins，增加这样的代码：\n1 2 3 plugins { id(\u0026#34;com.gradleup.shadow\u0026#34;) version \u0026#34;8.3.3\u0026#34; } 然后增加shadow任务，同样还是在build.gradle.kts中增加一下代码：\n1 2 3 4 5 6 7 8 9 tasks { shadowJar { archiveBaseName.set(\u0026#34;nocrud\u0026#34;) archiveVersion.set(\u0026#34;\u0026#34;) manifest { attributes[\u0026#34;Main-Class\u0026#34;] = \u0026#34;cn.cola.nocrud.MainKt\u0026#34; } } } 这段代码以笔者的nocrud项目为例，在上面的代码中nocrud是你项目的名称，attributes[\u0026quot;Main-Class\u0026quot;] = \u0026quot;cn.cola.nocrud.MainKt\u0026quot;则规定了主类。\n需要注意的是，如果你的主类是一个kotlin代码，则需要再原本的类名后面加上Kt，这是因为kotlin是一个jvm语言，编译后你会发现kotlin编译器会在所有的kotlin类名称后面加上Kt。\n完成了这些，刷新一下项目，你会发现idea的gradle菜单中新增了一个shadow任务，双击shadowJar命令执行即可打包。\n打包完的jar包在build/libs目录内。\n5.启动后端项目 在1panel-主机-文件中上传打包后的jar包。\n然后到网站-运行环境-java中运行后端项目。\n当然如果你的后端是go语言或php或nodejs那么就去对应的页面。\n本文以java项目为例，选择创建运行环境，设置名称和java sdk版本，将运行目录设置为jar包的上传目录。\n在启动命令一栏输入完整的启动命令，如\n1 java -jar ./teaai-backend-0.0.1-SNAPSHOT.jar 然后注意，1panel和宝塔面板有所不同，1panel的后端项目也是基于容器化部署的，需要填写应用在容器内的访问端口和容器外的端口。\n然后打开端口外部访问并设置容器名称。\n点击确定即可。\n最后提醒一下，因为1panel是容器化部署，而在容器内localhost指向的是容器内部的地址，如果想访问容器网外的本机的其他容器请使用本机的真实内网IP。\n6.部署其他中间件 这里需要根据中间件的不同进行部署，如关系型数据库需要建表等。\n7.打包前端项目 这里以打包teaai项目为例，teaai是一个vue项目。\n用WebStrom打开teaai前端项目，一般而言当你利用vue-cli创建项目时，在package.json中有这样的命令。\n1 \u0026#34;build\u0026#34;: \u0026#34;run-p type-check \\\u0026#34;build-only {@}\\\u0026#34; --\u0026#34;, 你可以直接点击WebStorm左边的运行按钮运行，也可以在终端中输入\n1 npm run build 打包项目。\n当然，如果你用pnpm或yarn等运行这个命令也一样。\n打包后你将在dist目录下看到打包后的结果。\n8.启动前端项目 进入1panel-网站-运行环境-php创建一个php运行环境，拓展模版选择“默认”即可。\n然后去你的DNS服务商配置域名解析（这个因服务商而不同，在此无法演示）。\n接下来进入1panel面板-网站-网站，如果你没有安装OpenResty（你可以理解为nginx增强版）则1panel会提示你安装。\n在网站页面选择创建网站-运行环境-选择刚刚创建的php运行环境\n（如果你的网站是静态网站也可以不创建php运行环境而直接选静态网站）\n输入网站的域名和需要访问的端口号,点击确定。\n你会看到1panel页面的表格中多了一条记录，点击其中的网站目录下的文件夹图标，进入文件界面上传前端打包的dist目录的内容。\n接着。如果要设置代理和https服务的话，回到刚刚的1panel-网站-网站页面，点击网站记录右边的配置，在这里可以对网站进行限流、反向代理、配置HTTPS服务等操作。\n如果开启了https服务，记得在防火墙打开443端口！\n","date":"2024-11-08T19:39:09+08:00","permalink":"https://ColaBlack.github.io/p/%E5%88%A9%E7%94%A81panel%E9%83%A8%E7%BD%B2%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E9%A1%B9%E7%9B%AE-java%E4%BB%A3%E7%A0%81%E6%89%93%E5%8C%85-%E5%89%8D%E7%AB%AF%E6%89%93%E5%8C%85/","title":"利用1panel部署前后端分离项目 Java代码打包 前端打包"},{"content":"初次发布于我的个人文档\n参考:智谱ai官方文档\n1.安装依赖 在maven 的pom.xml中输入\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;cn.bigmodel.openapi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;oapi-java-sdk\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;release-V4-2.3.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2.编写通用AI调用工具类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 package edu.zafu.teaai.utils; import com.zhipu.oapi.ClientV4; import com.zhipu.oapi.Constants; import com.zhipu.oapi.service.v4.model.*; import edu.zafu.teaai.constant.AiConfig; import io.reactivex.Flowable; import java.util.ArrayList; import java.util.List; /** * AI调用模块 * * @author ColaBlack */ public class AiUtils { /** * 业务ID模版 */ private static final String REQUEST_ID_TEMPLATE = \u0026#34;teaAI-request-%s\u0026#34;; /** * AI调用客户端 */ private static final ClientV4 CLIENT = new ClientV4.Builder(AiConfig.API_KEY).build(); /** * 调用AI接口(同步) * * @param prompt 提示词 * @return AI返回的答案 */ public static String aiCaller(String prompt) { List\u0026lt;ChatMessage\u0026gt; messages = new ArrayList\u0026lt;\u0026gt;(); ChatMessage chatMessage = new ChatMessage(ChatMessageRole.USER.value(), prompt); messages.add(chatMessage); String requestId = String.format(REQUEST_ID_TEMPLATE, System.currentTimeMillis()); ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder() .model(AiConfig.MODEL_NAME) .stream(Boolean.FALSE) .invokeMethod(Constants.invokeMethod) .messages(messages) .requestId(requestId) .build(); ModelApiResponse invokeModelApiResp = CLIENT.invokeModelApi(chatCompletionRequest); return invokeModelApiResp.getData().getChoices().get(0).getMessage().getContent().toString(); } /** * 调用AI接口(SSE) * * @author ColaBlack */ public static Flowable\u0026lt;ModelData\u0026gt; aiCallerFlow(String prompt) { List\u0026lt;ChatMessage\u0026gt; messages = new ArrayList\u0026lt;\u0026gt;(); ChatMessage chatMessage = new ChatMessage(ChatMessageRole.USER.value(), prompt); messages.add(chatMessage); String requestId = String.format(REQUEST_ID_TEMPLATE, System.currentTimeMillis()); ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder() .model(AiConfig.MODEL_NAME). stream(Boolean.TRUE). invokeMethod(Constants.invokeMethod) .messages(messages) .requestId(requestId) .build(); ModelApiResponse invokeModelApiResp = CLIENT.invokeModelApi(chatCompletionRequest); return invokeModelApiResp.getFlowable(); } } 3.配置信息 将代码中的AiConfig.MODEL_NAME替换为要使用的模型名称，AiConfig.API_KEY替换为你的API_KEY\n4.调用AI 如果要同步调用AI，那就直接将全部的提示词传入aiCaller方法，耐心等待即可返回结果。\n这里消息的生产速度往往大于消费速度，因此可以考虑介入消息队列MQ。\n同步调用如果一直让用户长时间等待用户体验不好，可以使用流式调用。\n将全部的提示词传入aiCallerFlow方法得到一个Flowable对象。\n为了将AI响应的结果传给前端，可以采用轮询、SSE、WebSocket等方式。这里选择使用SSE将响应由服务端推送给前端。\n这里的代码是传入全部的提示词，返回一个SseEmitter对象给前端，方便前端使用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 public SseEmitter generateQuestionSSE(String prompt) { // 建立 SSE 连接对象，0 表示不超时 SseEmitter emitter = new SseEmitter(0L); // AI 生成的流式响应结果 Flowable\u0026lt;ModelData\u0026gt; modelDataFlowable = AiUtils.aiCallerFlow(prompt); modelDataFlowable // 指定观察者的线程池 .observeOn(Schedulers.io()) // 从智谱的响应中获取数据 .map(chunk -\u0026gt; chunk.getChoices().get(0).getDelta().getContent()) // 去掉响应中多余的空格 .map(message -\u0026gt; message.replaceAll(\u0026#34;\\\\s\u0026#34;, \u0026#34;\u0026#34;)) // 去掉为空字符串的响应 .filter(StringUtils::isNotBlank) .flatMap(message -\u0026gt; { // 将字符串转换为字符数组以便后续业务处理 List\u0026lt;Character\u0026gt; charList = new ArrayList\u0026lt;\u0026gt;(); for (char c : message.toCharArray()) { charList.add(c); } return Flowable.fromIterable(charList); }) .doOnNext(c -\u0026gt; { // 进行业务处理 // 然后发送结果，这里为了演示直接不进行处理将给一个字符c都全部如实发送 emitter.send(c); }) //当AI响应完毕时关闭SSE .doOnComplete(emitter::complete) // 订阅AI响应流 .subscribe(); return emitter; } 4.前端接受SSE消息\n这里选择使用原生的方式接收。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 const handleSSE = async () =\u0026gt; { // 发送sse请求 const eventSource = new EventSource(REQUEST_URL) //传入请求地址 // 按项目给予用户生产中提示 alert(\u0026#39;生成中，请稍后\u0026#39;) // 开始监听sse消息 eventSource.onmessage = (event) =\u0026gt; { //解析后端推送的消息，这里以后端传JSON字符串为例 const res = JSON.parse(event.data) //进行处理，以追加到form.test为例 form.value.test = [...(form.value.test || []), res] } //处理报错和停止接受 eventSource.onerror = (event) =\u0026gt; { //正常停止接收 if (event.eventPhase === EventSource.CLOSED) { eventSource.close() alert(\u0026#39;生成结束\u0026#39;) } else { //报错记录日志 eventSource.close() console.error(\u0026#39;生成失败\u0026#39;) } } } ","date":"2024-11-04T19:35:19+08:00","permalink":"https://ColaBlack.github.io/p/%E6%99%BA%E8%B0%B1ai-java-sdk%E8%B0%83%E7%94%A8%E5%89%8D%E5%90%8E%E7%AB%AF%E6%93%8D%E4%BD%9C/","title":"智谱AI java SDK调用（前后端操作）"},{"content":"初次发布于我的个人文档\n参考资料 [FreeMarker官方文档（英文）](Apache FreeMarker Manual)\nFreeMarker 中文官方参考手册\nPicocli官方文档（英文）\npicocli-中文博客\n1.安装依赖 1 2 3 4 // https://mvnrepository.com/artifact/org.freemarker/freemarker implementation(\u0026#34;org.freemarker:freemarker:2.3.33\u0026#34;) // https://mvnrepository.com/artifact/info.picocli/picocli implementation(\u0026#34;info.picocli:picocli:4.7.6\u0026#34;) 2.编写Freemarker demo 参考官方文档，编写一个简单Freemarker的demo，生成一个Java文件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 import freemarker.template.Configuration import freemarker.template.TemplateExceptionHandler import java.io.File import java.io.OutputStreamWriter fun main() { // 创建配置对象 val config = Configuration(Configuration.VERSION_2_3_33) // 设置模板文件存放的目录 config.setDirectoryForTemplateLoading(File(\u0026#34;src/main/resources/templates\u0026#34;)) // 设置默认的编码格式 config.defaultEncoding = \u0026#34;UTF-8\u0026#34; // 设置异常处理器 config.templateExceptionHandler = TemplateExceptionHandler.RETHROW_HANDLER /* 利用HashMap创建数据模型 { \u0026#34;user\u0026#34;: \u0026#34;Big Joe\u0026#34;, \u0026#34;latestProduct\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;https://github.com/ColaBlack\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;No CRUD\u0026#34; } */ val hashMap = HashMap\u0026lt;String, Any\u0026gt;() hashMap[\u0026#34;user\u0026#34;] = \u0026#34;ColaBlack\u0026#34; val latest: MutableMap\u0026lt;String, Any\u0026gt; = HashMap() hashMap[\u0026#34;latestProduct\u0026#34;] = latest latest[\u0026#34;url\u0026#34;] = \u0026#34;https://github.com/ColaBlack\u0026#34; latest[\u0026#34;name\u0026#34;] = \u0026#34;No CRUD\u0026#34; // 获取模板文件 val template = config.getTemplate(\u0026#34;demo.ftl\u0026#34;) val out = OutputStreamWriter(File(\u0026#34;src/main/java/edu/zafu/generated/demo.java\u0026#34;).outputStream()) // 输出渲染后的内容 template.process(hashMap, out) // 关闭输出流 out.close() } 对应的模版文件demo.ftl如下：\n1 2 3 4 5 6 7 8 9 package edu.zafu.generated; public class demo { public static void main(String[] args) { System.out.println(\u0026#34;Hello ${user}\u0026#34;); System.out.println(\u0026#34;The latest product is ${latestProduct.name}\u0026#34;); System.out.println(\u0026#34;You can find it at ${latestProduct.url}\u0026#34;); } } 将模版文件放入src/main/resources/templates目录下，运行main 函数，将生成的Java文件输出到src/main/java/edu/zafu/generated/demo.java文件中。\n3.编写命令行picocli demo 参考官方文档，编写一个命令行demo，实现一个简单的ls命令。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 import picocli.CommandLine import picocli.CommandLine.* import java.io.File import kotlin.system.exitProcess /** * ls命令demo * * @author ColaBlack */ // 定义一个dir命令，name为ls，description为该命令的描述信息，mixinStandardHelpOptions为true，表示该命令需要自动生成help选项 @Command(name = \u0026#34;dir\u0026#34;, description = [\u0026#34;列出当前目录的目录结构\u0026#34;], mixinStandardHelpOptions = true) // 定义一个dir类，继承Runnable接口，实现run方法，用于执行ls命令，其中Callable的泛型int表示call方法的返回值类型 class Dir : Runnable { // 该参数在命令行中指定，索引为0，description为描述信息 @Parameters(index = \u0026#34;0\u0026#34;, description = [\u0026#34;要列出的目录路径\u0026#34;]) var path: String? = null // 定义一个path变量，用于接收命令行参数 // 该选项缩写为-a，全称为--all，description为描述信息 @Option(names = [\u0026#34;-a\u0026#34;, \u0026#34;--all\u0026#34;], description = [\u0026#34;显示所有文件，包括隐藏文件\u0026#34;]) var showHidden = false // 定义一个showHidden变量，用于接收-a选项，是否显示隐藏文件 // 用户执行命令时，会调用run方法 override fun run() { if (path == null) { println(\u0026#34;文件路径不能为空\u0026#34;) return } val file = File(path!!) if (!file.exists()) { // 判断目录是否存在 println(\u0026#34;文件路径不存在: $path\u0026#34;) return } if (!file.isDirectory) { // 判断是否为目录 println(\u0026#34;$path 不是一个目录\u0026#34;) return } val files = file.listFiles() if (files == null) { // 判断目录是否为空 println(\u0026#34;目录为空\u0026#34;) return } for (item in files) { if (showHidden || !item.name.startsWith(\u0026#34;.\u0026#34;)) { println(item.name) } } } } fun main(args: Array\u0026lt;String\u0026gt;) { val exitCode = CommandLine(Dir()).execute(*args) // 执行命令 exitProcess(exitCode) // 退出程序 } 运行main函数并设置参数就可以使用CLI\n4.编写需要制作成模版的代码 编写需要制作成模版的代码，例如本项目的controller代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 package $cn.cola.controller; import cn.cola.model.dto.user.UserUpdateRequest; import cn.cola.model.dto.user.UserQueryRequest; import cn.cola.model.dto.user.UserAddRequest; import cn.cola.common.constant.UserConstant; import cn.cola.common.exception.ThrowUtils; import cn.cola.common.DeleteRequest; import cn.cola.common.BaseResponse; import cn.cola.common.ResultUtils; import cn.cola.common.AuthCheck; import cn.cola.common.ErrorCode; import cn.cola.model.po.User; import cn.cola.model.vo.UserVO; import cn.cola.service.UserService; import com.baomidou.mybatisplus.extension.plugins.pagination.Page; import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper; import org.springframework.web.bind.annotation.*; import org.springframework.beans.BeanUtils; import lombok.extern.slf4j.Slf4j; import javax.annotation.Resource; import java.util.List; /** * 用户接口 * * @author ColaBlack */ @RestController @RequestMapping(\u0026#34;/user\u0026#34;) @Slf4j public class UserController { @Resource private UserService userService; // region 增删改查 /** * 插入用户（仅管理员） * * @param userAddRequest 用户添加请求体 * @return 新增的用户ID */ @PostMapping(\u0026#34;/insert\u0026#34;) @AuthCheck(mustRole = UserConstant.ADMIN_ROLE) public BaseResponse\u0026lt;Long\u0026gt; insertUser(@RequestBody UserAddRequest userAddRequest) { ThrowUtils.throwIf(userAddRequest == null, ErrorCode.PARAMS_ERROR, \u0026#34;参数不能为空\u0026#34;); ThrowUtils.throwIf(userAddRequest.getUserAccount() == null || userAddRequest.getUserAccount().isEmpty(), ErrorCode.PARAMS_ERROR, \u0026#34;账号不能为空\u0026#34;); User user = new User(); BeanUtils.copyProperties(userAddRequest, user); int res = userService.getBaseMapper().insert(user); ThrowUtils.throwIf(res \u0026lt;= 0, ErrorCode.OPERATION_ERROR, \u0026#34;数据库异常，增加用户失败\u0026#34;); return ResultUtils.success(user.getId()); } /** * 删除用户(仅管理员) * * @param deleteRequest 删除请求体 * @return 删除的记录数 */ @PostMapping(\u0026#34;/delete\u0026#34;) @AuthCheck(mustRole = UserConstant.ADMIN_ROLE) public BaseResponse\u0026lt;Integer\u0026gt; deleteUser(@RequestBody DeleteRequest deleteRequest) { ThrowUtils.throwIf(deleteRequest == null, ErrorCode.PARAMS_ERROR, \u0026#34;参数不能为空\u0026#34;); ThrowUtils.throwIf(deleteRequest.getId() \u0026lt;= 0, ErrorCode.PARAMS_ERROR, \u0026#34;参数错误\u0026#34;); int res = userService.getBaseMapper().deleteById(deleteRequest.getId()); ThrowUtils.throwIf(res \u0026lt;= 0, ErrorCode.OPERATION_ERROR, \u0026#34;数据库异常，删除用户失败\u0026#34;); return ResultUtils.success(res); } /** * 修改用户(仅管理员) * * @param userUpdateRequest 用户更新请求体 * @return 更新的记录数 */ @PostMapping(\u0026#34;/update\u0026#34;) @AuthCheck(mustRole = UserConstant.ADMIN_ROLE) public BaseResponse\u0026lt;Integer\u0026gt; updateUser(@RequestBody UserUpdateRequest userUpdateRequest) { ThrowUtils.throwIf(userUpdateRequest == null, ErrorCode.PARAMS_ERROR, \u0026#34;参数不能为空\u0026#34;); ThrowUtils.throwIf(userUpdateRequest.getId() \u0026lt;= 0, ErrorCode.PARAMS_ERROR, \u0026#34;参数错误\u0026#34;); User user = new User(); BeanUtils.copyProperties(userUpdateRequest, user); int res = userService.getBaseMapper().updateById(user); ThrowUtils.throwIf(res \u0026lt;= 0, ErrorCode.OPERATION_ERROR); return ResultUtils.success(res); } /** * 分页查询用户列表（仅管理员） * * @param userQueryRequest 条件查询请求体 * @return 用户列表 */ @PostMapping(\u0026#34;/select/page\u0026#34;) @AuthCheck(mustRole = UserConstant.ADMIN_ROLE) public BaseResponse\u0026lt;Page\u0026lt;User\u0026gt;\u0026gt; selectUserByPage(@RequestBody UserQueryRequest userQueryRequest) { long current = userQueryRequest.getCurrent(); long size = userQueryRequest.getPageSize(); ThrowUtils.throwIf(current \u0026lt;= 0 || size \u0026lt;= 0 || size \u0026gt; 100, ErrorCode.PARAMS_ERROR, \u0026#34;参数错误\u0026#34;); Page\u0026lt;User\u0026gt; page = new Page\u0026lt;\u0026gt;(current, size); QueryWrapper\u0026lt;User\u0026gt; queryWrapper = userService.getQueryWrapper(userQueryRequest); Page\u0026lt;User\u0026gt; res = userService.getBaseMapper().selectPage(page, queryWrapper); return ResultUtils.success(res); } /** * 根据ID查询用户信息（仅管理员） * * @param userQueryRequest 条件查询请求体 * @return 用户信息 */ @PostMapping(\u0026#34;/select/id\u0026#34;) @AuthCheck(mustRole = UserConstant.ADMIN_ROLE) public BaseResponse\u0026lt;User\u0026gt; selectUserById(@RequestBody UserQueryRequest userQueryRequest) { ThrowUtils.throwIf(userQueryRequest == null, ErrorCode.PARAMS_ERROR, \u0026#34;参数不能为空\u0026#34;); ThrowUtils.throwIf(userQueryRequest.getId() \u0026lt;= 0, ErrorCode.PARAMS_ERROR, \u0026#34;参数错误\u0026#34;); User user = userService.getBaseMapper().selectById(userQueryRequest.getId()); return ResultUtils.success(user); } /** * 根据ID查询用户信息（全体用户） */ @GetMapping(\u0026#34;/get/id\u0026#34;) public BaseResponse\u0026lt;UserVO\u0026gt; getUserById(@RequestParam(\u0026#34;id\u0026#34;) long id) { ThrowUtils.throwIf(id \u0026lt;= 0, ErrorCode.PARAMS_ERROR, \u0026#34;参数错误\u0026#34;); User user = userService.getBaseMapper().selectById(id); UserVO userVO = new UserVO(); BeanUtils.copyProperties(user, userVO); return ResultUtils.success(userVO); } /** * 分页查询用户信息（全体用户） */ @PostMapping(\u0026#34;/get/page\u0026#34;) public BaseResponse\u0026lt;Page\u0026lt;UserVO\u0026gt;\u0026gt; getUserByPage(@RequestBody UserQueryRequest userQueryRequest) { long current = userQueryRequest.getCurrent(); long size = userQueryRequest.getPageSize(); ThrowUtils.throwIf(current \u0026lt;= 0 || size \u0026lt;= 0 || size \u0026gt; 20, ErrorCode.PARAMS_ERROR, \u0026#34;参数错误\u0026#34;); Page\u0026lt;User\u0026gt; page = new Page\u0026lt;\u0026gt;(current, size); QueryWrapper\u0026lt;User\u0026gt; queryWrapper = userService.getQueryWrapper(userQueryRequest); Page\u0026lt;User\u0026gt; res = userService.getBaseMapper().selectPage(page, queryWrapper); Page\u0026lt;UserVO\u0026gt; userVoPage = new Page\u0026lt;\u0026gt;(); BeanUtils.copyProperties(res, userVoPage); List\u0026lt;UserVO\u0026gt; records = userVoPage.getRecords(); records.clear(); for (User user : res.getRecords()) { UserVO userVO = new UserVO(); BeanUtils.copyProperties(user, userVO); records.add(userVO); } return ResultUtils.success(userVoPage); } // endregion // region 其他接口 // todo: 此处补充其他接口 // endregion } 这个文档最先是在我的另一个个人文档网站的，但是在文档迁移的时候这个文件出了问题，里面的内容是我手工复原的，这段模版代码可能有问题，但是这不影响这篇文章的内容。\n5.编写FreeMarker模版 将原代码中可以被参数化的部分用${}包裹起来就得到了模版，例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 package ${packageName}.controller; import ${packageName}.model.dto.${key}.${upperKey}UpdateRequest; import ${packageName}.model.dto.${key}.${upperKey}QueryRequest; import ${packageName}.model.dto.${key}.${upperKey}AddRequest; import ${packageName}.common.constant.${upperKey}Constant; import ${packageName}.common.exception.ThrowUtils; import ${packageName}.common.DeleteRequest; import ${packageName}.common.BaseResponse; import ${packageName}.common.ResultUtils; import ${packageName}.common.AuthCheck; import ${packageName}.common.ErrorCode; import ${packageName}.model.po.${upperKey}; import ${packageName}.model.vo.${upperKey}VO; import ${packageName}.service.${upperKey}Service; import com.baomidou.mybatisplus.extension.plugins.pagination.Page; import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper; import org.springframework.web.bind.annotation.*; import org.springframework.beans.BeanUtils; import lombok.extern.slf4j.Slf4j; import javax.annotation.Resource; import java.util.List; /** * ${name}接口 * * @author ${author} */ @RestController @RequestMapping(\u0026#34;/${key}\u0026#34;) @Slf4j public class ${upperKey}Controller { @Resource private ${upperKey}Service ${key}Service; // region 增删改查 /** * 插入${name}（仅管理员） * * @param ${key}AddRequest ${name}添加请求体 * @return 新增的${name}ID */ @PostMapping(\u0026#34;/insert\u0026#34;) @AuthCheck(mustRole = UserConstant.ADMIN_ROLE) public BaseResponse\u0026lt;Long\u0026gt; insert${upperKey}(@RequestBody ${upperKey}AddRequest ${key}AddRequest) { ThrowUtils.throwIf(${key}AddRequest == null, ErrorCode.PARAMS_ERROR, \u0026#34;参数不能为空\u0026#34;); ThrowUtils.throwIf(${key}AddRequest.get${upperKey}Account() == null || ${key}AddRequest.get${upperKey}Account().isEmpty(), ErrorCode.PARAMS_ERROR, \u0026#34;账号不能为空\u0026#34;); ${upperKey} ${key} = new ${upperKey}(); BeanUtils.copyProperties(${key}AddRequest, ${key}); int res = ${key}Service.getBaseMapper().insert(${key}); ThrowUtils.throwIf(res \u0026lt;= 0, ErrorCode.OPERATION_ERROR, \u0026#34;数据库异常，增加${name}失败\u0026#34;); return ResultUtils.success(${key}.getId()); } /** * 删除${name}(仅管理员) * * @param deleteRequest 删除请求体 * @return 删除的记录数 */ @PostMapping(\u0026#34;/delete\u0026#34;) @AuthCheck(mustRole = $UserConstant.ADMIN_ROLE) public BaseResponse\u0026lt;Integer\u0026gt; delete${upperKey}(@RequestBody DeleteRequest deleteRequest) { ThrowUtils.throwIf(deleteRequest == null, ErrorCode.PARAMS_ERROR, \u0026#34;参数不能为空\u0026#34;); ThrowUtils.throwIf(deleteRequest.getId() \u0026lt;= 0, ErrorCode.PARAMS_ERROR, \u0026#34;参数错误\u0026#34;); int res = ${key}Service.getBaseMapper().deleteById(deleteRequest.getId()); ThrowUtils.throwIf(res \u0026lt;= 0, ErrorCode.OPERATION_ERROR, \u0026#34;数据库异常，删除${name}失败\u0026#34;); return ResultUtils.success(res); } /** * 修改${name}(仅管理员) * * @param ${key}UpdateRequest ${name}更新请求体 * @return 更新的记录数 */ @PostMapping(\u0026#34;/update\u0026#34;) @AuthCheck(mustRole = $UserConstant.ADMIN_ROLE) public BaseResponse\u0026lt;Integer\u0026gt; update${upperKey}(@RequestBody ${upperKey}UpdateRequest ${key}UpdateRequest) { ThrowUtils.throwIf(${key}UpdateRequest == null, ErrorCode.PARAMS_ERROR, \u0026#34;参数不能为空\u0026#34;); ThrowUtils.throwIf(${key}UpdateRequest.getId() \u0026lt;= 0, ErrorCode.PARAMS_ERROR, \u0026#34;参数错误\u0026#34;); ${upperKey} ${key} = new ${upperKey}(); BeanUtils.copyProperties(${key}UpdateRequest, ${key}); int res = ${key}Service.getBaseMapper().updateById(${key}); ThrowUtils.throwIf(res \u0026lt;= 0, ErrorCode.OPERATION_ERROR); return ResultUtils.success(res); } /** * 分页查询${name}列表（仅管理员） * * @param ${key}QueryRequest 条件查询请求体 * @return ${name}列表 */ @PostMapping(\u0026#34;/select/page\u0026#34;) @AuthCheck(mustRole = $UserConstant.ADMIN_ROLE) public BaseResponse\u0026lt;Page\u0026lt;${upperKey}\u0026gt;\u0026gt; select${upperKey}ByPage(@RequestBody ${upperKey}QueryRequest ${key}QueryRequest) { long current = ${key}QueryRequest.getCurrent(); long size = ${key}QueryRequest.getPageSize(); ThrowUtils.throwIf(current \u0026lt;= 0 || size \u0026lt;= 0 || size \u0026gt; 100, ErrorCode.PARAMS_ERROR, \u0026#34;参数错误\u0026#34;); Page\u0026lt;${upperKey}\u0026gt; page = new Page\u0026lt;\u0026gt;(current, size); QueryWrapper\u0026lt;${upperKey}\u0026gt; queryWrapper = ${key}Service.getQueryWrapper(${key}QueryRequest); Page\u0026lt;${upperKey}\u0026gt; res = ${key}Service.getBaseMapper().selectPage(page, queryWrapper); return ResultUtils.success(res); } /** * 根据ID查询${name}信息（仅管理员） * * @param ${key}QueryRequest 条件查询请求体 * @return ${name}信息 */ @PostMapping(\u0026#34;/select/id\u0026#34;) @AuthCheck(mustRole = $UserConstant.ADMIN_ROLE) public BaseResponse\u0026lt;${upperKey}\u0026gt; select${upperKey}ById(@RequestBody ${upperKey}QueryRequest ${key}QueryRequest) { ThrowUtils.throwIf(${key}QueryRequest == null, ErrorCode.PARAMS_ERROR, \u0026#34;参数不能为空\u0026#34;); ThrowUtils.throwIf(${key}QueryRequest.getId() \u0026lt;= 0, ErrorCode.PARAMS_ERROR, \u0026#34;参数错误\u0026#34;); ${upperKey} ${key} = ${key}Service.getBaseMapper().selectById(${key}QueryRequest.getId()); return ResultUtils.success(${key}); } /** * 根据ID查询${name}信息（全体用户） */ @GetMapping(\u0026#34;/get/id\u0026#34;) public BaseResponse\u0026lt;${upperKey}VO\u0026gt; get${upperKey}ById(@RequestParam(\u0026#34;id\u0026#34;) long id) { ThrowUtils.throwIf(id \u0026lt;= 0, ErrorCode.PARAMS_ERROR, \u0026#34;参数错误\u0026#34;); ${upperKey} ${key} = ${key}Service.getBaseMapper().selectById(id); ${upperKey}VO ${key}VO = new ${upperKey}VO(); BeanUtils.copyProperties(${key}, ${key}VO); return ResultUtils.success(${key}VO); } /** * 分页查询${name}信息（全体用户） */ @PostMapping(\u0026#34;/get/page\u0026#34;) public BaseResponse\u0026lt;Page\u0026lt;${upperKey}VO\u0026gt;\u0026gt; get${upperKey}ByPage(@RequestBody ${upperKey}QueryRequest ${key}QueryRequest) { long current = ${key}QueryRequest.getCurrent(); long size = ${key}QueryRequest.getPageSize(); ThrowUtils.throwIf(current \u0026lt;= 0 || size \u0026lt;= 0 || size \u0026gt; 20, ErrorCode.PARAMS_ERROR, \u0026#34;参数错误\u0026#34;); Page\u0026lt;${upperKey}\u0026gt; page = new Page\u0026lt;\u0026gt;(current, size); QueryWrapper\u0026lt;${upperKey}\u0026gt; queryWrapper = ${key}Service.getQueryWrapper(${key}QueryRequest); Page\u0026lt;${upperKey}\u0026gt; res = ${key}Service.getBaseMapper().selectPage(page, queryWrapper); Page\u0026lt;${upperKey}VO\u0026gt; ${key}VoPage = new Page\u0026lt;\u0026gt;(); BeanUtils.copyProperties(res, ${key}VoPage); List\u0026lt;${upperKey}VO\u0026gt; records = ${key}VoPage.getRecords(); records.clear(); for (${upperKey} ${key} : res.getRecords()) { ${upperKey}VO ${key}VO = new ${upperKey}VO(); BeanUtils.copyProperties(${key}, ${key}VO); records.add(${key}VO); } return ResultUtils.success(${key}VoPage); } // endregion // region 其他接口 // todo: 此处补充其他接口 // endregion } 6.制作CLI工具 完整代码参考：No CRUD项目\n","date":"2024-10-29T19:35:19+08:00","permalink":"https://ColaBlack.github.io/p/%E7%B1%BBnocrud%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%E6%89%8B%E5%86%8C-%E6%A8%A1%E7%89%88%E5%BC%95%E6%93%8Efreemarker-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%88%B6%E4%BD%9C%E5%99%A8picocli/","title":"类NoCRUD项目开发手册 模版引擎FreeMarker 命令行制作器Picocli"},{"content":"初次发布于我的个人文档\n本文收集了一些常用的配置类，便于后续查询使用。\n后端常用配置 1.全局跨域配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 package edu.zafu.teaai.config; import org.springframework.context.annotation.Configuration; import org.springframework.web.servlet.config.annotation.CorsRegistry; import org.springframework.web.servlet.config.annotation.WebMvcConfigurer; /** * 全局跨域配置 * * @author ColaBlack */ @Configuration public class CorsConfig implements WebMvcConfigurer { @Override public void addCorsMappings(CorsRegistry registry) { // 覆盖所有请求 registry.addMapping(\u0026#34;/**\u0026#34;) // 允许发送 Cookie .allowCredentials(true) // 放行哪些域名（必须修改为你实际的域名，否则 * 会和 allowCredentials 冲突） .allowedOriginPatterns(\u0026#34;*\u0026#34;) .allowedMethods(\u0026#34;GET\u0026#34;, \u0026#34;POST\u0026#34;, \u0026#34;PUT\u0026#34;, \u0026#34;DELETE\u0026#34;, \u0026#34;OPTIONS\u0026#34;) .allowedHeaders(\u0026#34;*\u0026#34;) .exposedHeaders(\u0026#34;*\u0026#34;); } } 注意：放行的域名，allowedOriginPatterns()必须修改为前端的域名，否则会冲突。\n2.避免Long转json时的精度丢失 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 package edu.zafu.teaai.config; import com.fasterxml.jackson.databind.ObjectMapper; import com.fasterxml.jackson.databind.module.SimpleModule; import com.fasterxml.jackson.databind.ser.std.ToStringSerializer; import org.springframework.boot.jackson.JsonComponent; import org.springframework.context.annotation.Bean; import org.springframework.http.converter.json.Jackson2ObjectMapperBuilder; /** * 配置如何处理Json文本 * * @author ColaBlack */ @JsonComponent public class JsonConfig { /** * 添加 Long 转 json 精度丢失的配置 */ @Bean public ObjectMapper jacksonObjectMapper(Jackson2ObjectMapperBuilder builder) { ObjectMapper objectMapper = builder.createXmlMapper(false).build(); SimpleModule module = new SimpleModule(); module.addSerializer(Long.class, ToStringSerializer.instance); module.addSerializer(Long.TYPE, ToStringSerializer.instance); objectMapper.registerModule(module); return objectMapper; } } 在Java中Long类型是64位有符号整数，‌范围从-9,223,372,036,854,775,808到9,223,372,036,854,775,807，然而在JavaScript中整数最长只有15位，所以需要在Long类型对象进行序列化时将Long类型转化为字符串避免精度丢失。\n此时，如果传递一个Long类型的ID则前端收到的是一个字符串，就不会有精度问题。\n3.开启MyBatis分页功能 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package edu.zafu.teaai.config; import com.baomidou.mybatisplus.annotation.DbType; import com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor; import com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor; import org.mybatis.spring.annotation.MapperScan; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; /** * MyBatis Plus 配置 * * @author ColaBlack */ @Configuration @MapperScan(\u0026#34;edu.zafu.teaai.mapper\u0026#34;) public class MyBatisPlusConfig { /** * 拦截器配置 */ @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() { MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); // 分页插件 interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL)); return interceptor; } } Mybatis的分页功能需要以上配置才能开启。\n4.开启MyBatis下划线转驼峰、逻辑删除功能 1 2 3 4 5 6 7 8 9 mybatis-plus: configuration: map-underscore-to-camel-case: true # 驼峰命名 log-impl: org.apache.ibatis.logging.stdout.StdOutImpl global-config: db-config: logic-delete-field: is_delete # 全局逻辑删除的实体字段名 logic-delete-value: 1 # 逻辑已删除值（默认为 1） logic-not-delete-value: 0 # 逻辑未删除值（默认为 0） 需要在application.yml中增加以上配置。\n前端常用配置 1.前端为开发服务器开启代理解决跨域问题 1 2 3 4 5 6 7 8 9 server: { port: 1222, proxy: { \u0026#39;/api\u0026#39;: { target: \u0026#39;http://localhost:1221\u0026#39;, changeOrigin: true } } }, 在vite.config.ts的defineConfig函数传入的实参对象中增加这样的配置即可。\n其意义是，将前端开发服务器开在1222端口，将所有/api开头的请求代理到后端http://localhost:1221。\n以后只需要向前端服务器http://localhost:1222发请求即可。\n增加完之后你的配置文件可能长这样：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import { fileURLToPath, URL } from \u0026#39;node:url\u0026#39; import { defineConfig } from \u0026#39;vite\u0026#39; import vue from \u0026#39;@vitejs/plugin-vue\u0026#39; // https://vitejs.dev/config/ export default defineConfig({ server: { port: 3000, proxy: { \u0026#39;/api\u0026#39;: { target: \u0026#39;http://localhost:1221\u0026#39;, changeOrigin: true } } }, plugins: [ vue() ], resolve: { alias: { \u0026#39;@\u0026#39;: fileURLToPath(new URL(\u0026#39;./src\u0026#39;, import.meta.url)) } } }) 对于这个配置，官方文档是这样说明的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 export default defineConfig({ server: { proxy: { // 字符串简写写法：http://localhost:5173/foo -\u0026gt; http://localhost:4567/foo \u0026#39;/foo\u0026#39;: \u0026#39;http://localhost:4567\u0026#39;, // 带选项写法：http://localhost:5173/api/bar -\u0026gt; http://jsonplaceholder.typicode.com/bar \u0026#39;/api\u0026#39;: { target: \u0026#39;http://jsonplaceholder.typicode.com\u0026#39;, changeOrigin: true, rewrite: (path) =\u0026gt; path.replace(/^\\/api/, \u0026#39;\u0026#39;), }, // 正则表达式写法：http://localhost:5173/fallback/ -\u0026gt; http://jsonplaceholder.typicode.com/ \u0026#39;^/fallback/.*\u0026#39;: { target: \u0026#39;http://jsonplaceholder.typicode.com\u0026#39;, changeOrigin: true, rewrite: (path) =\u0026gt; path.replace(/^\\/fallback/, \u0026#39;\u0026#39;), }, // 使用 proxy 实例 \u0026#39;/api\u0026#39;: { target: \u0026#39;http://jsonplaceholder.typicode.com\u0026#39;, changeOrigin: true, configure: (proxy, options) =\u0026gt; { // proxy 是 \u0026#39;http-proxy\u0026#39; 的实例 } }, // 代理 websockets 或 socket.io 写法：ws://localhost:5173/socket.io -\u0026gt; ws://localhost:5174/socket.io // 在使用 `rewriteWsOrigin` 时要特别谨慎，因为这可能会让代理服务器暴露在 CSRF 攻击之下 \u0026#39;/socket.io\u0026#39;: { target: \u0026#39;ws://localhost:5174\u0026#39;, ws: true, rewriteWsOrigin: true, }, }, }, }) 官方文档链接：开发服务器选项 | Vite 官方中文文档\n2.配置axios请求 在src/config下创建request.ts用于配置axios。\n配置内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 import axios from \u0026#39;axios\u0026#39; export const BASE_URL = \u0026#39;http://localhost:1222\u0026#39; const request = axios.create({ baseURL: BASE_URL, timeout: 60000, withCredentials: true }) // 请求拦截器 request.interceptors.request.use( function (config) { // Do something before request is sent return config }, function (error) { // Do something with request error return Promise.reject(error) } ) // 响应拦截器 request.interceptors.response.use( function (response) { // Any status code that lie within the range of 2xx cause this function to trigger // Do something with response data const { data } = response // 未登录 if (data.code === 40100) { // 不是获取用户信息接口，并且不是登录页面，则跳转到登录页面并保存当前页面的路径 if ( !response.request.responseURL.includes(\u0026#39;user/get/login\u0026#39;) \u0026amp;\u0026amp; !window.location.pathname.includes(\u0026#39;/user/login\u0026#39;) ) { window.location.href = `/user/login?redirect=${window.location.href}` } } return response }, function (error) { // Any status codes that falls outside the range of 2xx cause this function to trigger // Do something with response error return Promise.reject(error) } ) export default request BASE_URL务必换成自己后端的地址（如果前端开了代理则为前端的地址），真实上线时请修改为真实的请求地址！\nwithCredentials: true请务必开启，否则cookie会有问题。\n3. Umijs/openapi 在有些时候，我们可能已经有了一份openapi格式的接口文档。（如：后端已经开发完成则可以使用swagger或knife4j自动生成接口文档）\n这时可以使用umijs/openapi自动生成请求代码。\n需要在src/config下新建openapi.config.js配置如下：\n1 2 3 4 5 6 7 import { generateService } from \u0026#39;@umijs/openapi\u0026#39; generateService({ requestLibPath: \u0026#34;import request from \u0026#39;@/config/request\u0026#39;\u0026#34;, schemaPath: \u0026#39;http://localhost:1221/api/v2/api-docs\u0026#39;, serversPath: \u0026#39;./src\u0026#39; }) 然后在package.json中增加如下运行脚本\n1 \u0026#34;openapi\u0026#34;: \u0026#34;node src/config/openapi.config.js\u0026#34; 4.Pinia存储用户登录态样例代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 import { defineStore } from \u0026#39;pinia\u0026#39; import type { Ref } from \u0026#39;vue\u0026#39; import { ref } from \u0026#39;vue\u0026#39; import { getLoginUserUsingGet } from \u0026#39;@/api/userController\u0026#39; import type { AxiosResponse } from \u0026#39;axios\u0026#39; import roleEnums from \u0026#39;@/access/roleEnums\u0026#39; export const useUserStore = defineStore(\u0026#39;USER_LOGIN_STATE\u0026#39;, () =\u0026gt; { const loginUser: Ref\u0026lt;API.LoginUserVO\u0026gt; = ref({ userName: \u0026#39;未登录\u0026#39; }) async function fetchLoginUser() { const res: AxiosResponse\u0026lt;API.BaseResponseLoginUserVO_\u0026gt; = await getLoginUserUsingGet() if (res.data.code === 200 \u0026amp;\u0026amp; res.data.data) { loginUser.value = res.data.data } else { loginUser.value = { userName: \u0026#39;未登录\u0026#39;, userRole: roleEnums.PUBLIC } } } function setLoginUser(newUser: API.LoginUserVO) { loginUser.value = newUser } return { loginUser, fetchLoginUser, setLoginUser } }) ","date":"2024-10-28T19:39:49+08:00","permalink":"https://ColaBlack.github.io/p/%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E7%B1%BB/","title":"常用配置类"},{"content":"初次发布于我的个人文档\n参考：\n1,MINIO在java中的使用\n2.MinIO Linux官方文档\n1.利用1panel安装minio 图片上传等服务依赖于对象存储服务，本文就以开源对象储存minio为例简单介绍。\n推荐使用linux版本的minio，只需在1panel应用商城傻瓜式安装即可。\n记得记好你的root账户用户名和密码，另外minio不支持弱密码弱用户名！\n1panel基于容器部署，记得开启外部访问权限。\n2.安装java sdk 1 2 3 4 5 6 \u0026lt;!-- https://mvnrepository.com/artifact/io.minio/minio --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.minio\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;minio\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.5.13\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 或\n1 2 // https://mvnrepository.com/artifact/io.minio/minio implementation(\u0026#34;io.minio:minio:8.5.13\u0026#34;) 3.配置minio连接 在applicantion.yml添加如下配置。\n1 2 3 4 minio: endpoint: http://你的minio主机:9000 accesskey: 你的ak secretkwy: 你的sk 注意，minio默认9000端口是上传文件的端口，9001是其web控制台端口，ak‘和sk都可以在那里获取。\n然后新增配置类：\n先配置如何在applicantion.yml中读取配置信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 package edu.zafu.teaai.config; import lombok.Data; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.stereotype.Component; /** * 获取minio的配置信息 * * @author ColaBlack */ @Data @Component @ConfigurationProperties(prefix = \u0026#34;minio\u0026#34;) // 此处说明了要读取minio.*的配置信息 public class MinioProps { /** * minio的url */ private String endpoint; /** * minio的ak */ private String accesskey; /** * minio的sk */ private String secretkwy; } 然后是真正着手配置minio\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package edu.zafu.teaai.config; import io.minio.MinioClient; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import javax.annotation.Resource; /** * minio配置类 * * @author ColaBlack */ @Configuration public class MinioConfig { @Resource private MinioProps props; /** * 获取 Minio客户端对象 * * @return MinioClient */ @Bean public MinioClient minioClient() { return MinioClient.builder() .endpoint(props.getEndpoint()) .credentials(props.getAccesskey(), props.getSecretkwy()) .build(); } } 最后是在minio上传文件的工具类。\n这也是重点中的重点。\n对象存储以存储桶为基本单位，你可以粗略得认为存储桶就是一个“数据库”，下面来介绍一下如何创建存储桶。\n当然，事实上这个存储桶应该由管理员在minio web界面上创建而不是用java程序创建。不过无妨，这里也讲讲。\n我们要通过刚刚配置的minio客户端对minio进行操作，所以要先通过依赖注入获取客户端。\n1 2 @Resource private MinioClient client; 然后再写一个方法创建指定名称的存储桶。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * 创建桶 * * @param bucketName 桶名称 */ public void createBucket(String bucketName) { boolean found = client.bucketExists( BucketExistsArgs.builder(). bucket(bucketName) .build() ); if (!found) { client.makeBucket( MakeBucketArgs.builder() .bucket(bucketName) .build()); } } 第一段代码是通过客户端的bucketExists方法判断指定名称的存储桶是否存在。\n但是我们还得给他传一个查询参数才行，这就是括号里面传的参数了。\n通过\n1 BucketExistsArgs.builder().bucket(bucketName).build() 即可得到一个查询桶名称为字符串bucketName内容的桶。\n如果存在这样的桶则found=true，反之为false。\n下一段则是说，如果桶不存在，那就通过client.makeBucket创建桶。\n当然，你可能会发现idea报error说方法可能抛出两个异常，你可以通过try catch手动捕获异常进行处理，也可以加上lombok的@SneakyThrows交由lombok自动处理。\n最后上传文件的工具方法就变成了\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Resource private MinioClient client; /** * 上传文件 * * @param bucketName 桶名称 * @param objectName 文件名 * @param stream 输入流 * @param fileSize 文件大小 */ @SneakyThrows public void putObject(String bucketName, String objectName, InputStream stream, Long fileSize) { client.putObject( PutObjectArgs.builder() .bucket(bucketName) .object(objectName) .stream(stream, fileSize, -1) .build()); } 删除桶啊什么的自己看文档吧，实际上暂时只有上传文件和获取文件的URL会用到。\n上传文件则需要文件的输入流stream等信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * 上传文件 * * @param bucketName 桶名称 * @param objectName 文件名 * @param stream 输入流 * @param fileSize 文件大小 * @param type 文件类型 */ @SneakyThrows public void putObject(String bucketName, String objectName, InputStream stream, Long fileSize, String type) { client.putObject( PutObjectArgs.builder() .bucket(bucketName) .object(objectName) .stream(stream, fileSize, -1) .contentType(type) .build()); } 需要注意的是，一般而言文件类型minio可以自己根据后缀名自己识别，在这里可以不给出。\n常见的文件类型\ntext/plain: 文本文件（.txt） text/html: HTML文件（.html, .htm） application/json: JSON文件（.json） application/xml: XML文件（.xml） image/jpeg: JPEG图片（.jpg, .jpeg） image/png: PNG图片（.png） image/gif: GIF图片（.gif） application/pdf: PDF文件（.pdf） application/zip: ZIP文件（.zip） 所以最简单的上传方法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /** * 上传文件 * * @param bucketName 桶名称 * @param objectName 文件名 * @param stream 输入流 * @param fileSize 文件大小 */ @SneakyThrows public void putObject(String bucketName, String objectName, InputStream stream, Long fileSize) { client.putObject( PutObjectArgs.builder() .bucket(bucketName) .object(objectName) .stream(stream, fileSize, -1) .build()); } 还有一个需要的是获取文件的外链，也就是外部可以访问的URL信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 /** * 获取文件在minio在服务器上的外链 * * @param bucketName 桶名称 * @param objectName 文件名 * @return 外链 */ @SneakyThrows public String getObjectUrl(String bucketName, String objectName) { return client.getPresignedObjectUrl( GetPresignedObjectUrlArgs.builder() .method(Method.GET) .bucket(bucketName) .object(objectName) .build()); } 其他的方法可以自己查询文档获取，使用率并不高。\n最终整个工具类的代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 package edu.zafu.teaai.utils; import io.minio.GetPresignedObjectUrlArgs; import io.minio.MinioClient; import io.minio.PutObjectArgs; import io.minio.http.Method; import lombok.SneakyThrows; import org.springframework.stereotype.Component; import javax.annotation.Resource; import java.io.InputStream; /** * minio操作类 * * @author ColaBlack */ @Component public class MinioUtils { @Resource private MinioClient client; /** * 上传文件 * * @param bucketName 桶名称 * @param objectName 文件名 * @param stream 输入流 * @param fileSize 文件大小 */ @SneakyThrows public void putObject(String bucketName, String objectName, InputStream stream, Long fileSize) { client.putObject( PutObjectArgs.builder() .bucket(bucketName) .object(objectName) .stream(stream, fileSize, -1) .build()); } /** * 获取文件在minio在服务器上的外链 * * @param bucketName 桶名称 * @param objectName 文件名 * @return 外链 */ @SneakyThrows public String getObjectUrl(String bucketName, String objectName) { return client.getPresignedObjectUrl( GetPresignedObjectUrlArgs.builder() .method(Method.GET) .bucket(bucketName) .object(objectName) .build()); } } 4.编写工具类和service层代码 本文以头像上传为例进行简介。\n首先编写service层接口代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 package edu.zafu.teaai.service; import edu.zafu.teaai.model.dto.file.UploadFileRequest; import org.springframework.web.multipart.MultipartFile; import javax.servlet.http.HttpServletRequest; /** * minio文件服务接口 * * @author ColaBlack */ public interface MinioService { /** * 上传文件 * * @param file 上传的文件 * @param uploadFileRequest 上传文件请求 * @param request 请求对象 * @return 上传结果 */ String uploadImage( MultipartFile file, UploadFileRequest uploadFileRequest, HttpServletRequest request); /** * 验证文件 * * @param file 文件 */ void validFile(MultipartFile file); } 接着在编写实现类时会遇到几个常量， 在此提前给出。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /** * 文件上传相关常量 * * @author ColaBlack */ public interface FileConstant { /** * 上传文件最大大小1MB */ int MAX_FILE_SIZE = 1048576; /** * 允许上传的图片类型 */ List\u0026lt;String\u0026gt; ALLOW_IMAGE_TYPES = Arrays.asList(\u0026#34;jpg\u0026#34;, \u0026#34;jpeg\u0026#34;, \u0026#34;png\u0026#34;, \u0026#34;svg\u0026#34;, \u0026#34;webp\u0026#34;, \u0026#34;bmp\u0026#34;); } 这两个常量都是用于验证头像信息的。\n然后是编写实现类，首先是验证图片信息的方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * 校验文件 * * @param file 文件 */ @Override public void validFile(MultipartFile file) { ThrowUtils.throwIf(ObjectUtils.isEmpty(file), ErrorCode.PARAMS_ERROR, \u0026#34;文件不能为空\u0026#34;); // 文件大小 long fileSize = file.getSize(); if (fileSize \u0026gt; FileConstant.MAX_FILE_SIZE) { throw new BusinessException(ErrorCode.PARAMS_ERROR, \u0026#34;文件大小不能超过 1M\u0026#34;); } // 文件后缀 String fileSuffix = FileUtil.getSuffix(file.getOriginalFilename()); if (!FileConstant.ALLOW_IMAGE_TYPES.contains(fileSuffix)) { throw new BusinessException(ErrorCode.PARAMS_ERROR, \u0026#34;文件类型错误\u0026#34;); } } 主要是对文件大小和文件类型进行了限制。\n然后是重头戏，操作minio上传文件。\n在上传文件前需要根据业务进行一些检查，例如只有已登录用户才能上传头像等等，在此只调用刚刚写的validFile方法。\n1 2 // 校验文件 validFile(file); 然后是对用户上传的头像进行重命名，避免两个不同的用户上传了同一名字的图片导致异常覆盖。\n本文以：业务名_当前时间戳_随机uuid_文件原始名称为重命名模版。\n1 2 3 //重命名文件 FileUploadBizEnum fileUploadBizEnum = FileUploadBizEnum.getEnumByValue(biz); String fileName = biz + \u0026#34;_\u0026#34; + System.currentTimeMillis() + \u0026#34;_\u0026#34; + UUID.randomUUID() + \u0026#34;_\u0026#34; + file.getOriginalFilename(); 然后调用minioUtils的方法上传文件即可。\n1 2 3 4 //使用minio上传文件 minioUtils.putObject(FileConstant.BUCKET_NAME, fileName, file.getInputStream(), file.getSize()); //获取外链 return minioUtils.getObjectUrl(FileConstant.BUCKET_NAME, fileName); 最后minio服务实现类的代码就是\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 package edu.zafu.teaai.service.impl; import cn.hutool.core.io.FileUtil; import edu.zafu.teaai.common.ErrorCode; import edu.zafu.teaai.common.exception.BusinessException; import edu.zafu.teaai.common.exception.ThrowUtils; import edu.zafu.teaai.constant.FileConstant; import edu.zafu.teaai.constant.UserConstant; import edu.zafu.teaai.service.MinioService; import edu.zafu.teaai.utils.MinioUtils; import lombok.SneakyThrows; import org.apache.commons.lang3.ObjectUtils; import org.springframework.stereotype.Service; import org.springframework.web.multipart.MultipartFile; import javax.annotation.Resource; import javax.servlet.http.HttpServletRequest; import java.util.UUID; /** * Minio文件服务实现类 * * @author ColaBlack */ @Service public class MinioServiceImpl implements MinioService { @Resource private MinioUtils minioUtils; /** * 上传文件 * * @param file 上传的文件 * @param biz 业务类型 * @param request 请求对象 * @return 上传结果 */ @SneakyThrows @Override public String uploadImage(MultipartFile file, String biz, HttpServletRequest request) { // 校验文件 validFile(file); //登录用户才能上传文件 Object attribute = request.getSession().getAttribute(UserConstant.USER_LOGIN_STATE); ThrowUtils.throwIf(ObjectUtils.isEmpty(attribute), ErrorCode.NOT_LOGIN_ERROR, \u0026#34;用户未登录\u0026#34;); //重命名文件 String fileName = biz + \u0026#34;_\u0026#34; + System.currentTimeMillis() + \u0026#34;_\u0026#34; + UUID.randomUUID() + \u0026#34;_\u0026#34; + file.getOriginalFilename(); //使用minio上传文件 minioUtils.putObject(FileConstant.BUCKET_NAME, fileName, file.getInputStream(), file.getSize()); //获取外链 return minioUtils.getObjectUrl(FileConstant.BUCKET_NAME, fileName); } /** * 校验文件 * * @param file 文件 */ @Override public void validFile(MultipartFile file) { ThrowUtils.throwIf(ObjectUtils.isEmpty(file), ErrorCode.PARAMS_ERROR, \u0026#34;文件不能为空\u0026#34;); // 文件大小 long fileSize = file.getSize(); if (fileSize \u0026gt; FileConstant.MAX_FILE_SIZE) { throw new BusinessException(ErrorCode.PARAMS_ERROR, \u0026#34;文件大小不能超过 1M\u0026#34;); } // 文件后缀 String fileSuffix = FileUtil.getSuffix(file.getOriginalFilename()); if (!FileConstant.ALLOW_IMAGE_TYPES.contains(fileSuffix)) { throw new BusinessException(ErrorCode.PARAMS_ERROR, \u0026#34;文件类型错误\u0026#34;); } } } 最后提醒一下，别忘了service层实现类要有Service注解。\n5.编写controller层代码 在编写前需要先针对项目的业务编写枚举类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 package edu.zafu.teaai.model.enums; import lombok.AllArgsConstructor; import lombok.Getter; import org.apache.commons.lang3.ObjectUtils; import java.util.Arrays; import java.util.List; import java.util.stream.Collectors; /** * 文件上传业务类型枚举 * * @author ColaBlack */ @Getter @AllArgsConstructor public enum FileUploadBizEnum { /** * 用户头像上传 */ USER_AVATAR(\u0026#34;用户头像\u0026#34;, \u0026#34;user_avatar\u0026#34;), /** * 业务类型名称 */ private final String text; /** * 业务类型值 */ private final String value; /** * 获取值列表 */ public static List\u0026lt;String\u0026gt; getValues() { return Arrays.stream(values()).map(item -\u0026gt; item.value).collect(Collectors.toList()); } /** * 根据 value 获取枚举 */ public static FileUploadBizEnum getEnumByValue(String value) { if (ObjectUtils.isEmpty(value)) { return null; } for (FileUploadBizEnum anEnum : FileUploadBizEnum.values()) { if (anEnum.value.equals(value)) { return anEnum; } } return null; } } 在controller层，先注入minioService，然后进行简单的校验\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Resource private MinioService minioService; @PostMapping(\u0026#34;/upload/avatar\u0026#34;) public BaseResponse\u0026lt;String\u0026gt; uploadAvatar(@RequestPart(\u0026#34;file\u0026#34;) MultipartFile file, UploadFileRequest uploadFileRequest, HttpServletRequest request) { //登录用户才能上传文件 Object attribute = request.getSession().getAttribute(UserConstant.USER_LOGIN_STATE); ThrowUtils.throwIf(ObjectUtils.isEmpty(attribute), ErrorCode.NOT_LOGIN_ERROR, \u0026#34;用户未登录\u0026#34;); // 校验业务类型 String biz = uploadFileRequest.getBiz(); FileUploadBizEnum fileUploadBizEnum = FileUploadBizEnum.getEnumByValue(biz); ThrowUtils.throwIf(!Objects.equals(fileUploadBizEnum, FileUploadBizEnum.USER_AVATAR), ErrorCode.PARAMS_ERROR, \u0026#34;上传业务类型不正确\u0026#34;); // 上传文件 String res = minioService.uploadImage(file, biz, request); return ResultUtils.success(res); } 然后调用service层代码即可。\n","date":"2024-10-27T19:40:47+08:00","permalink":"https://ColaBlack.github.io/p/minio%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8-%E5%9B%BE%E7%89%87-%E5%9B%BE%E7%89%87%E4%B8%8A%E4%BC%A0-%E5%A4%B4%E5%83%8F/","title":"Minio对象存储 图片 图片上传 头像"},{"content":"初次发布于我的个人文档\n参考：缓存雪崩，缓存击穿，缓存穿透 Caffeine本地缓存\n在一些场景下可以引入缓存加速，利用redis实现缓存通常是一个不错的选择，但有时为了避免系统变得复杂可以使用本地缓存。 Caffeine就是一个高效的本地缓存组件。使用方式如下：\n1.安装依赖 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.ben-manes.caffeine\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;caffeine\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.9.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2.创建用于缓存的key-value键值对 1 2 3 4 5 6 Cache\u0026lt;String, String\u0026gt; answerCacheMap = Caffeine.newBuilder() //初始化缓存键值对容量 .initialCapacity(1024) // 设置缓存有效期为一天 .expireAfterAccess(1L, TimeUnit.DAYS) .build(); 利用缓存是为了提高速度，但是缓存的数据并不会及时更新，所以需要设置有效期，即 超时是为了保证数据的有效。缓存有效期需要根据业务的不同自行设置。\n3.新增和读取缓存 1 2 3 4 5 6 7 8 9 // 从刚刚的缓存键值对中读取缓存的cacheKey对应的数据 String cache = answerCacheMap.getIfPresent(cacheKey); // 如果没有命中缓存，则取出的cache字符串为空 if (StringUtils.isEmpty(cache)) { // 未命中缓存，走正常的业务逻辑 cache = work(); // 缓存结果 answerCacheMap.put(cacheKey, json); } 4.缓存的问题 无论用什么方式实现缓存都需要注意以下几个问题：\n缓存击穿 缓存击穿指在某一个时间有大量同一个key对应的缓存键值对过期或redis、caffeine等缓存中间件故障，与此同时客户端直接向业务系统（如数据库）发起请求，从而导致业务系统接着崩溃。\n解决方法有： 预防性缓存更新：在热点数据即将过期时，提前异步刷新缓存。通过检测热点数据的访问频率，当即将过期时触发自动更新操作，避免过期瞬间的击穿问题。 双缓存机制：可以采用双层缓存策略：一个主要缓存层负责缓存大部分数据，另一个次缓存层保存上次的缓存数据。在主要缓存失效时，可以直接从次缓存层读取数据，避免直接打到业务系统。 加锁保证同时只有少量请求能够构建缓存和访问业务系统\n缓存雪崩 缓存雪崩指在某一个时间有大量不同的key对应的缓存键值对过期或redis、caffeine等缓存中间件故障，与此同时客户端直接向业务系统（如数据库）发起请求，从而导致业务系统接着崩溃。\n解决方法有： 将过期时间进行一定范围内的随机化 使用多级缓存 加锁保证同时只有少量请求能够构建缓存和访问业务系统 使用redis高可用集群等确保缓存尽量少得故障。\n缓存穿透 缓存穿透指用户恶意查询业务系统中本不可能存在的key导致每次请求都直接穿过缓存机制访问业务系统，如果恶意用户进行大量这样的查询则会导致业务系统因压力过大而崩溃。 解决方法： 缓存空结果：如果查询的某个键在业务系统中不应该存在，则将该键的查询结果（如 null 或空值）缓存起来，并设定一个较短的过期时间，防止该键反复查询打到业务系统。 阻止非法请求（使用黑名单机制）：在查询请求进入业务系统前，进行严格的参数校验和过滤，避免不合法的请求查询业务系统（避免黑名单内的请求进入）。 使用白名单机制：使用布隆过滤器对所有可能存在的数据进行标记（设为白名单），所有请求先经过布隆过滤器进行校验，只有布隆过滤器认为存在的数据（白名单的数据），才会去查询缓存或数据库。这样可以有效拦截掉绝大多数不存在的请求，防止这些请求绕过缓存直接打到数据库。\n","date":"2024-10-23T19:43:38+08:00","permalink":"https://ColaBlack.github.io/p/caffeine%E6%9C%AC%E5%9C%B0%E7%BC%93%E5%AD%98%E5%92%8C%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9-%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF-%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F/","title":"Caffeine本地缓存和缓存雪崩 缓存击穿 缓存穿透"},{"content":"初次发布于我的个人文档\n参考:java操作163邮箱\n本文以163邮箱为例，介绍如何用java发送邮箱。\n1.获取邮箱授权码 进入163邮箱-设置-POP3/SMTP/IMAP-开启POP3/SMTP服务\n记录得到的授权码\n2.安装依赖 1 2 3 4 // https://mvnrepository.com/artifact/jakarta.activation/jakarta.activation-api implementation(\u0026#34;jakarta.activation:jakarta.activation-api:2.1.3\u0026#34;) // https://mvnrepository.com/artifact/org.apache.commons/commons-email implementation(\u0026#34;org.apache.commons:commons-email:1.6.0\u0026#34;) 注意，参考文章年代有些久远，有几个库已经合并更新换了新的名字。\n3.编写通用邮件发送工具类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 package edu.zafu; import org.apache.commons.mail.EmailException; import org.apache.commons.mail.SimpleEmail; /** * 邮件工具类 * * @author ColaBlack */ public class MailUtils { /** * 发送邮件 * * @param targetEmail 目标用户邮箱 * @param header 邮件的标题 * @param message 要发送的消息 */ public static void sendEmail(String targetEmail, String header, String message) { try { // 创建邮箱对象 SimpleEmail mail = new SimpleEmail(); // 设置发送邮件的服务器，以163邮箱为例 mail.setHostName(\u0026#34;smtp.163.com\u0026#34;); // 输入发送邮件的邮箱号+授权码 mail.setAuthentication(\u0026#34;用于发送的邮箱号\u0026#34;, \u0026#34;授权码\u0026#34;); // 注意：一个邮箱账号可能有多个邮箱，要注意这个区分。 // 如QQ邮箱就支持同一个邮箱账号持有@qq.com @foxmail.com两个邮箱 // 发送邮件 \u0026#34;你的邮箱号\u0026#34;+\u0026#34;发送时用的昵称\u0026#34; mail.setFrom(\u0026#34;用于发送邮箱的邮箱号\u0026#34;, \u0026#34;昵称\u0026#34;); // 使用SSL安全链接 mail.setSSLOnConnect(true); // 接收用户的邮箱 mail.addTo(targetEmail); // 邮件的主题(标题) mail.setSubject(header); // 邮件的内容 mail.setMsg(message); // 发送 mail.send(); } catch (EmailException e) { // 邮件发送失败，记录日志(此处应该换成项目统一的日志记录方式) System.out.println(\u0026#34;邮件发送失败：\u0026#34; + e.getMessage()); } } } 4.调用工具类——以发验证码为例 编写发送验证码工具类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package edu.zafu; import java.util.Random; /** * 发送验证码工具类 * * @author ColaBlack */ public class SendCode { /** * 发送验证码 * * @param targetEmail 目标邮箱 */ public static void send(String targetEmail) { // 生成验证码 int code = new Random().nextInt(899999) + 100000; // 发送验证码 MailUtils.sendEmail(targetEmail, \u0026#34;验证码\u0026#34;, \u0026#34;您的验证码为:\u0026#34; + code + \u0026#34;(1分钟内有效)\u0026#34;); } } 可以使用如下代码测试\n1 2 3 4 5 6 7 8 9 10 11 12 package edu.zafu; /** * 测试邮箱发送 * * @author ColaBlack */ public class TestMail { public static void main(String[] args) { SendCode.send(\u0026#34;你的第二个邮箱\u0026#34;); } } 5.引入缓存机制 上面的验证码用户可以通过疯狂发送请求而恶意消耗邮箱发送资源，我们也没有让验证码及时过期。\n可以引入缓存机制解决，在上文Caffeine本地缓存和缓存雪崩，缓存击穿，缓存穿透中我们介绍了如何利用caffeine实现本地缓存，本文就选择用 Redis 实现分布式缓存。\n6.安装Redisson 为了在java中操作redis需要安装依赖\n1 2 // https://mvnrepository.com/artifact/org.redisson/redisson implementation(\u0026#34;org.redisson:redisson:3.37.0\u0026#34;) 7.调整验证码工具类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 package edu.zafu; import org.redisson.Redisson; import org.redisson.api.RMapCache; import org.redisson.api.RedissonClient; import org.redisson.config.Config; import java.util.Random; import java.util.concurrent.TimeUnit; /** * 发送验证码工具类 * * @author ColaBlack */ public class SendCode { /** * 发送验证码 * * @param targetEmail 目标邮箱 */ public static void send(String targetEmail) { Config config = new Config(); config.useSingleServer() // 使用单机模式 // 设置要连接的数据库 .setDatabase(0) // 设置redis服务器地址 .setAddress(\u0026#34;redis://127.0.0.1:6379\u0026#34;) // 设置redis密码 .setPassword(\u0026#34;password\u0026#34;); // 创建Redisson客户端 RedissonClient redisson = Redisson.create(config); // 获取缓存的map RMapCache\u0026lt;Object, Object\u0026gt; codeCache = redisson.getMapCache(\u0026#34;code\u0026#34;); // 判断目标邮箱是否已存在验证码 if (codeCache.containsKey(targetEmail)) { // 验证码已存在，直接返回 return; } // 验证码不存在，生成验证码并存入缓存 // 生成验证码 int code = new Random().nextInt(899999) + 100000; // 存入缓存,设置1分钟过期 codeCache.put(targetEmail, code, 1, TimeUnit.MINUTES); // 发送验证码 MailUtils.sendEmail(targetEmail, \u0026#34;验证码\u0026#34;, \u0026#34;您的验证码为:\u0026#34; + code + \u0026#34;(1分钟内有效)\u0026#34;); // 校验验证码是否正确时也从redis中拿去对应邮箱的验证码，这样就能实现验证码的超时过期 } } 关于使用缓存机制可能引发的缓存击穿、缓存雪崩、缓存穿透的问题请参考上文Caffeine本地缓存和缓存雪崩，缓存击穿，缓存穿透\n","date":"2024-10-23T19:41:34+08:00","permalink":"https://ColaBlack.github.io/p/java%E6%93%8D%E4%BD%9C%E9%82%AE%E7%AE%B1-%E9%82%AE%E7%AE%B1%E5%8F%91%E9%80%81%E9%AA%8C%E8%AF%81%E7%A0%81-redis%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98-redisson%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/","title":"Java操作邮箱 邮箱发送验证码 Redis分布式缓存 Redisson分布式缓存"}]